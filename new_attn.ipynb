{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SparseFlash2LinformerAttention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEGIN FORWARD\n",
      "x input shape: torch.Size([32, 1024, 512])\n",
      "x_reshaped shape: torch.Size([32, 1024, 8, 64])\n",
      "values : torch.Size([32, 1024, 8, 64])\n",
      "queries : torch.Size([32, 1024, 8, 128])\n",
      "keys : torch.Size([32, 1024, 8, 128])\n",
      "attention_scores after random projection: torch.Size([32, 8, 1024, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 0, Partition End 128 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 128, Partition End 256 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 256, Partition End 384 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 384, Partition End 512 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 512, Partition End 640 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 640, Partition End 768 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 768, Partition End 896 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 896, Partition End 1024 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "values shape: torch.Size([32, 8, 1024, 64])\n",
      "values.reshape(-1, self.head_dim) shape: torch.Size([262144, 64])\n",
      "self.value_projection(values) shape: torch.Size([262144, 128])\n",
      "projected_values shape: torch.Size([32, 8, 1024, 128])\n",
      "2ND EINSUM\n",
      "out shape: torch.Size([32, 8, 1024])\n",
      "BEGIN FORWARD\n",
      "x input shape: torch.Size([32, 1024, 512])\n",
      "x_reshaped shape: torch.Size([32, 1024, 8, 64])\n",
      "values : torch.Size([32, 1024, 8, 64])\n",
      "queries : torch.Size([32, 1024, 8, 128])\n",
      "keys : torch.Size([32, 1024, 8, 128])\n",
      "attention_scores after random projection: torch.Size([32, 8, 1024, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 0, Partition End 128 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 128, Partition End 256 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 256, Partition End 384 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 384, Partition End 512 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 512, Partition End 640 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 640, Partition End 768 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 768, Partition End 896 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 896, Partition End 1024 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "values shape: torch.Size([32, 8, 1024, 64])\n",
      "values.reshape(-1, self.head_dim) shape: torch.Size([262144, 64])\n",
      "self.value_projection(values) shape: torch.Size([262144, 128])\n",
      "projected_values shape: torch.Size([32, 8, 1024, 128])\n",
      "2ND EINSUM\n",
      "out shape: torch.Size([32, 8, 1024])\n",
      "BEGIN FORWARD\n",
      "x input shape: torch.Size([32, 1024, 512])\n",
      "x_reshaped shape: torch.Size([32, 1024, 8, 64])\n",
      "values : torch.Size([32, 1024, 8, 64])\n",
      "queries : torch.Size([32, 1024, 8, 128])\n",
      "keys : torch.Size([32, 1024, 8, 128])\n",
      "attention_scores after random projection: torch.Size([32, 8, 1024, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 0, Partition End 128 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 128, Partition End 256 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 256, Partition End 384 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 384, Partition End 512 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 512, Partition End 640 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 640, Partition End 768 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 768, Partition End 896 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 896, Partition End 1024 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "values shape: torch.Size([32, 8, 1024, 64])\n",
      "values.reshape(-1, self.head_dim) shape: torch.Size([262144, 64])\n",
      "self.value_projection(values) shape: torch.Size([262144, 128])\n",
      "projected_values shape: torch.Size([32, 8, 1024, 128])\n",
      "2ND EINSUM\n",
      "out shape: torch.Size([32, 8, 1024])\n",
      "BEGIN FORWARD\n",
      "x input shape: torch.Size([4, 1024, 512])\n",
      "x_reshaped shape: torch.Size([4, 1024, 8, 64])\n",
      "values : torch.Size([4, 1024, 8, 64])\n",
      "queries : torch.Size([4, 1024, 8, 128])\n",
      "keys : torch.Size([4, 1024, 8, 128])\n",
      "attention_scores after random projection: torch.Size([4, 8, 1024, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([4, 128, 8, 128])\n",
      "Partition Start 0, Partition End 128 , ponder_scores: torch.Size([4, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([4, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([4, 128, 8, 128])\n",
      "queries_part shape: torch.Size([4, 128, 8, 128])\n",
      "C_keys shape: torch.Size([4, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([4, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([4, 128, 8, 128])\n",
      "attention shape: torch.Size([4, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([4, 128, 8, 128])\n",
      "Partition Start 128, Partition End 256 , ponder_scores: torch.Size([4, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([4, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([4, 128, 8, 128])\n",
      "queries_part shape: torch.Size([4, 128, 8, 128])\n",
      "C_keys shape: torch.Size([4, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([4, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([4, 128, 8, 128])\n",
      "attention shape: torch.Size([4, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([4, 128, 8, 128])\n",
      "Partition Start 256, Partition End 384 , ponder_scores: torch.Size([4, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([4, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([4, 128, 8, 128])\n",
      "queries_part shape: torch.Size([4, 128, 8, 128])\n",
      "C_keys shape: torch.Size([4, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([4, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([4, 128, 8, 128])\n",
      "attention shape: torch.Size([4, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([4, 128, 8, 128])\n",
      "Partition Start 384, Partition End 512 , ponder_scores: torch.Size([4, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([4, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([4, 128, 8, 128])\n",
      "queries_part shape: torch.Size([4, 128, 8, 128])\n",
      "C_keys shape: torch.Size([4, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([4, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([4, 128, 8, 128])\n",
      "attention shape: torch.Size([4, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([4, 128, 8, 128])\n",
      "Partition Start 512, Partition End 640 , ponder_scores: torch.Size([4, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([4, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([4, 128, 8, 128])\n",
      "queries_part shape: torch.Size([4, 128, 8, 128])\n",
      "C_keys shape: torch.Size([4, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([4, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([4, 128, 8, 128])\n",
      "attention shape: torch.Size([4, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([4, 128, 8, 128])\n",
      "Partition Start 640, Partition End 768 , ponder_scores: torch.Size([4, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([4, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([4, 128, 8, 128])\n",
      "queries_part shape: torch.Size([4, 128, 8, 128])\n",
      "C_keys shape: torch.Size([4, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([4, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([4, 128, 8, 128])\n",
      "attention shape: torch.Size([4, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([4, 128, 8, 128])\n",
      "Partition Start 768, Partition End 896 , ponder_scores: torch.Size([4, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([4, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([4, 128, 8, 128])\n",
      "queries_part shape: torch.Size([4, 128, 8, 128])\n",
      "C_keys shape: torch.Size([4, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([4, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([4, 128, 8, 128])\n",
      "attention shape: torch.Size([4, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([4, 128, 8, 128])\n",
      "Partition Start 896, Partition End 1024 , ponder_scores: torch.Size([4, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([4, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([4, 128, 8, 128])\n",
      "queries_part shape: torch.Size([4, 128, 8, 128])\n",
      "C_keys shape: torch.Size([4, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([4, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([4, 128, 8, 128])\n",
      "attention shape: torch.Size([4, 128, 8, 128])\n",
      "values shape: torch.Size([4, 8, 1024, 64])\n",
      "values.reshape(-1, self.head_dim) shape: torch.Size([32768, 64])\n",
      "self.value_projection(values) shape: torch.Size([32768, 128])\n",
      "projected_values shape: torch.Size([4, 8, 1024, 128])\n",
      "2ND EINSUM\n",
      "out shape: torch.Size([4, 8, 1024])\n",
      "Epoch: 0, Loss: 2.27197265625\n",
      "BEGIN FORWARD\n",
      "x input shape: torch.Size([32, 1024, 512])\n",
      "x_reshaped shape: torch.Size([32, 1024, 8, 64])\n",
      "values : torch.Size([32, 1024, 8, 64])\n",
      "queries : torch.Size([32, 1024, 8, 128])\n",
      "keys : torch.Size([32, 1024, 8, 128])\n",
      "attention_scores after random projection: torch.Size([32, 8, 1024, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 0, Partition End 128 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 128, Partition End 256 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 256, Partition End 384 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 384, Partition End 512 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 512, Partition End 640 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 640, Partition End 768 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 768, Partition End 896 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 896, Partition End 1024 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "values shape: torch.Size([32, 8, 1024, 64])\n",
      "values.reshape(-1, self.head_dim) shape: torch.Size([262144, 64])\n",
      "self.value_projection(values) shape: torch.Size([262144, 128])\n",
      "projected_values shape: torch.Size([32, 8, 1024, 128])\n",
      "2ND EINSUM\n",
      "out shape: torch.Size([32, 8, 1024])\n",
      "BEGIN FORWARD\n",
      "x input shape: torch.Size([32, 1024, 512])\n",
      "x_reshaped shape: torch.Size([32, 1024, 8, 64])\n",
      "values : torch.Size([32, 1024, 8, 64])\n",
      "queries : torch.Size([32, 1024, 8, 128])\n",
      "keys : torch.Size([32, 1024, 8, 128])\n",
      "attention_scores after random projection: torch.Size([32, 8, 1024, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 0, Partition End 128 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 128, Partition End 256 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 256, Partition End 384 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 384, Partition End 512 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 512, Partition End 640 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 640, Partition End 768 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 768, Partition End 896 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 896, Partition End 1024 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "values shape: torch.Size([32, 8, 1024, 64])\n",
      "values.reshape(-1, self.head_dim) shape: torch.Size([262144, 64])\n",
      "self.value_projection(values) shape: torch.Size([262144, 128])\n",
      "projected_values shape: torch.Size([32, 8, 1024, 128])\n",
      "2ND EINSUM\n",
      "out shape: torch.Size([32, 8, 1024])\n",
      "BEGIN FORWARD\n",
      "x input shape: torch.Size([32, 1024, 512])\n",
      "x_reshaped shape: torch.Size([32, 1024, 8, 64])\n",
      "values : torch.Size([32, 1024, 8, 64])\n",
      "queries : torch.Size([32, 1024, 8, 128])\n",
      "keys : torch.Size([32, 1024, 8, 128])\n",
      "attention_scores after random projection: torch.Size([32, 8, 1024, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 0, Partition End 128 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 128, Partition End 256 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 256, Partition End 384 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 384, Partition End 512 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 512, Partition End 640 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 640, Partition End 768 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 768, Partition End 896 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 896, Partition End 1024 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "values shape: torch.Size([32, 8, 1024, 64])\n",
      "values.reshape(-1, self.head_dim) shape: torch.Size([262144, 64])\n",
      "self.value_projection(values) shape: torch.Size([262144, 128])\n",
      "projected_values shape: torch.Size([32, 8, 1024, 128])\n",
      "2ND EINSUM\n",
      "out shape: torch.Size([32, 8, 1024])\n",
      "BEGIN FORWARD\n",
      "x input shape: torch.Size([4, 1024, 512])\n",
      "x_reshaped shape: torch.Size([4, 1024, 8, 64])\n",
      "values : torch.Size([4, 1024, 8, 64])\n",
      "queries : torch.Size([4, 1024, 8, 128])\n",
      "keys : torch.Size([4, 1024, 8, 128])\n",
      "attention_scores after random projection: torch.Size([4, 8, 1024, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([4, 128, 8, 128])\n",
      "Partition Start 0, Partition End 128 , ponder_scores: torch.Size([4, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([4, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([4, 128, 8, 128])\n",
      "queries_part shape: torch.Size([4, 128, 8, 128])\n",
      "C_keys shape: torch.Size([4, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([4, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([4, 128, 8, 128])\n",
      "attention shape: torch.Size([4, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([4, 128, 8, 128])\n",
      "Partition Start 128, Partition End 256 , ponder_scores: torch.Size([4, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([4, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([4, 128, 8, 128])\n",
      "queries_part shape: torch.Size([4, 128, 8, 128])\n",
      "C_keys shape: torch.Size([4, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([4, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([4, 128, 8, 128])\n",
      "attention shape: torch.Size([4, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([4, 128, 8, 128])\n",
      "Partition Start 256, Partition End 384 , ponder_scores: torch.Size([4, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([4, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([4, 128, 8, 128])\n",
      "queries_part shape: torch.Size([4, 128, 8, 128])\n",
      "C_keys shape: torch.Size([4, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([4, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([4, 128, 8, 128])\n",
      "attention shape: torch.Size([4, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([4, 128, 8, 128])\n",
      "Partition Start 384, Partition End 512 , ponder_scores: torch.Size([4, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([4, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([4, 128, 8, 128])\n",
      "queries_part shape: torch.Size([4, 128, 8, 128])\n",
      "C_keys shape: torch.Size([4, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([4, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([4, 128, 8, 128])\n",
      "attention shape: torch.Size([4, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([4, 128, 8, 128])\n",
      "Partition Start 512, Partition End 640 , ponder_scores: torch.Size([4, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([4, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([4, 128, 8, 128])\n",
      "queries_part shape: torch.Size([4, 128, 8, 128])\n",
      "C_keys shape: torch.Size([4, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([4, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([4, 128, 8, 128])\n",
      "attention shape: torch.Size([4, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([4, 128, 8, 128])\n",
      "Partition Start 640, Partition End 768 , ponder_scores: torch.Size([4, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([4, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([4, 128, 8, 128])\n",
      "queries_part shape: torch.Size([4, 128, 8, 128])\n",
      "C_keys shape: torch.Size([4, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([4, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([4, 128, 8, 128])\n",
      "attention shape: torch.Size([4, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([4, 128, 8, 128])\n",
      "Partition Start 768, Partition End 896 , ponder_scores: torch.Size([4, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([4, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([4, 128, 8, 128])\n",
      "queries_part shape: torch.Size([4, 128, 8, 128])\n",
      "C_keys shape: torch.Size([4, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([4, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([4, 128, 8, 128])\n",
      "attention shape: torch.Size([4, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([4, 128, 8, 128])\n",
      "Partition Start 896, Partition End 1024 , ponder_scores: torch.Size([4, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([4, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([4, 128, 8, 128])\n",
      "queries_part shape: torch.Size([4, 128, 8, 128])\n",
      "C_keys shape: torch.Size([4, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([4, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([4, 128, 8, 128])\n",
      "attention shape: torch.Size([4, 128, 8, 128])\n",
      "values shape: torch.Size([4, 8, 1024, 64])\n",
      "values.reshape(-1, self.head_dim) shape: torch.Size([32768, 64])\n",
      "self.value_projection(values) shape: torch.Size([32768, 128])\n",
      "projected_values shape: torch.Size([4, 8, 1024, 128])\n",
      "2ND EINSUM\n",
      "out shape: torch.Size([4, 8, 1024])\n",
      "Epoch: 1, Loss: 2.3173828125\n",
      "BEGIN FORWARD\n",
      "x input shape: torch.Size([32, 1024, 512])\n",
      "x_reshaped shape: torch.Size([32, 1024, 8, 64])\n",
      "values : torch.Size([32, 1024, 8, 64])\n",
      "queries : torch.Size([32, 1024, 8, 128])\n",
      "keys : torch.Size([32, 1024, 8, 128])\n",
      "attention_scores after random projection: torch.Size([32, 8, 1024, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 0, Partition End 128 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 128, Partition End 256 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 256, Partition End 384 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 384, Partition End 512 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 512, Partition End 640 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 640, Partition End 768 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 768, Partition End 896 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 896, Partition End 1024 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "values shape: torch.Size([32, 8, 1024, 64])\n",
      "values.reshape(-1, self.head_dim) shape: torch.Size([262144, 64])\n",
      "self.value_projection(values) shape: torch.Size([262144, 128])\n",
      "projected_values shape: torch.Size([32, 8, 1024, 128])\n",
      "2ND EINSUM\n",
      "out shape: torch.Size([32, 8, 1024])\n",
      "BEGIN FORWARD\n",
      "x input shape: torch.Size([32, 1024, 512])\n",
      "x_reshaped shape: torch.Size([32, 1024, 8, 64])\n",
      "values : torch.Size([32, 1024, 8, 64])\n",
      "queries : torch.Size([32, 1024, 8, 128])\n",
      "keys : torch.Size([32, 1024, 8, 128])\n",
      "attention_scores after random projection: torch.Size([32, 8, 1024, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 0, Partition End 128 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 128, Partition End 256 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 256, Partition End 384 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 384, Partition End 512 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 512, Partition End 640 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 640, Partition End 768 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 768, Partition End 896 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 896, Partition End 1024 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "values shape: torch.Size([32, 8, 1024, 64])\n",
      "values.reshape(-1, self.head_dim) shape: torch.Size([262144, 64])\n",
      "self.value_projection(values) shape: torch.Size([262144, 128])\n",
      "projected_values shape: torch.Size([32, 8, 1024, 128])\n",
      "2ND EINSUM\n",
      "out shape: torch.Size([32, 8, 1024])\n",
      "BEGIN FORWARD\n",
      "x input shape: torch.Size([32, 1024, 512])\n",
      "x_reshaped shape: torch.Size([32, 1024, 8, 64])\n",
      "values : torch.Size([32, 1024, 8, 64])\n",
      "queries : torch.Size([32, 1024, 8, 128])\n",
      "keys : torch.Size([32, 1024, 8, 128])\n",
      "attention_scores after random projection: torch.Size([32, 8, 1024, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 0, Partition End 128 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 128, Partition End 256 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 256, Partition End 384 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 384, Partition End 512 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 512, Partition End 640 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 640, Partition End 768 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 768, Partition End 896 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 896, Partition End 1024 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "values shape: torch.Size([32, 8, 1024, 64])\n",
      "values.reshape(-1, self.head_dim) shape: torch.Size([262144, 64])\n",
      "self.value_projection(values) shape: torch.Size([262144, 128])\n",
      "projected_values shape: torch.Size([32, 8, 1024, 128])\n",
      "2ND EINSUM\n",
      "out shape: torch.Size([32, 8, 1024])\n",
      "BEGIN FORWARD\n",
      "x input shape: torch.Size([4, 1024, 512])\n",
      "x_reshaped shape: torch.Size([4, 1024, 8, 64])\n",
      "values : torch.Size([4, 1024, 8, 64])\n",
      "queries : torch.Size([4, 1024, 8, 128])\n",
      "keys : torch.Size([4, 1024, 8, 128])\n",
      "attention_scores after random projection: torch.Size([4, 8, 1024, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([4, 128, 8, 128])\n",
      "Partition Start 0, Partition End 128 , ponder_scores: torch.Size([4, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([4, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([4, 128, 8, 128])\n",
      "queries_part shape: torch.Size([4, 128, 8, 128])\n",
      "C_keys shape: torch.Size([4, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([4, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([4, 128, 8, 128])\n",
      "attention shape: torch.Size([4, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([4, 128, 8, 128])\n",
      "Partition Start 128, Partition End 256 , ponder_scores: torch.Size([4, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([4, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([4, 128, 8, 128])\n",
      "queries_part shape: torch.Size([4, 128, 8, 128])\n",
      "C_keys shape: torch.Size([4, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([4, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([4, 128, 8, 128])\n",
      "attention shape: torch.Size([4, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([4, 128, 8, 128])\n",
      "Partition Start 256, Partition End 384 , ponder_scores: torch.Size([4, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([4, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([4, 128, 8, 128])\n",
      "queries_part shape: torch.Size([4, 128, 8, 128])\n",
      "C_keys shape: torch.Size([4, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([4, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([4, 128, 8, 128])\n",
      "attention shape: torch.Size([4, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([4, 128, 8, 128])\n",
      "Partition Start 384, Partition End 512 , ponder_scores: torch.Size([4, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([4, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([4, 128, 8, 128])\n",
      "queries_part shape: torch.Size([4, 128, 8, 128])\n",
      "C_keys shape: torch.Size([4, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([4, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([4, 128, 8, 128])\n",
      "attention shape: torch.Size([4, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([4, 128, 8, 128])\n",
      "Partition Start 512, Partition End 640 , ponder_scores: torch.Size([4, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([4, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([4, 128, 8, 128])\n",
      "queries_part shape: torch.Size([4, 128, 8, 128])\n",
      "C_keys shape: torch.Size([4, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([4, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([4, 128, 8, 128])\n",
      "attention shape: torch.Size([4, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([4, 128, 8, 128])\n",
      "Partition Start 640, Partition End 768 , ponder_scores: torch.Size([4, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([4, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([4, 128, 8, 128])\n",
      "queries_part shape: torch.Size([4, 128, 8, 128])\n",
      "C_keys shape: torch.Size([4, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([4, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([4, 128, 8, 128])\n",
      "attention shape: torch.Size([4, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([4, 128, 8, 128])\n",
      "Partition Start 768, Partition End 896 , ponder_scores: torch.Size([4, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([4, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([4, 128, 8, 128])\n",
      "queries_part shape: torch.Size([4, 128, 8, 128])\n",
      "C_keys shape: torch.Size([4, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([4, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([4, 128, 8, 128])\n",
      "attention shape: torch.Size([4, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([4, 128, 8, 128])\n",
      "Partition Start 896, Partition End 1024 , ponder_scores: torch.Size([4, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([4, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([4, 128, 8, 128])\n",
      "queries_part shape: torch.Size([4, 128, 8, 128])\n",
      "C_keys shape: torch.Size([4, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([4, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([4, 128, 8, 128])\n",
      "attention shape: torch.Size([4, 128, 8, 128])\n",
      "values shape: torch.Size([4, 8, 1024, 64])\n",
      "values.reshape(-1, self.head_dim) shape: torch.Size([32768, 64])\n",
      "self.value_projection(values) shape: torch.Size([32768, 128])\n",
      "projected_values shape: torch.Size([4, 8, 1024, 128])\n",
      "2ND EINSUM\n",
      "out shape: torch.Size([4, 8, 1024])\n",
      "Epoch: 2, Loss: 2.29736328125\n",
      "BEGIN FORWARD\n",
      "x input shape: torch.Size([32, 1024, 512])\n",
      "x_reshaped shape: torch.Size([32, 1024, 8, 64])\n",
      "values : torch.Size([32, 1024, 8, 64])\n",
      "queries : torch.Size([32, 1024, 8, 128])\n",
      "keys : torch.Size([32, 1024, 8, 128])\n",
      "attention_scores after random projection: torch.Size([32, 8, 1024, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 0, Partition End 128 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 128, Partition End 256 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 256, Partition End 384 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 384, Partition End 512 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 512, Partition End 640 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 640, Partition End 768 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 768, Partition End 896 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 896, Partition End 1024 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "values shape: torch.Size([32, 8, 1024, 64])\n",
      "values.reshape(-1, self.head_dim) shape: torch.Size([262144, 64])\n",
      "self.value_projection(values) shape: torch.Size([262144, 128])\n",
      "projected_values shape: torch.Size([32, 8, 1024, 128])\n",
      "2ND EINSUM\n",
      "out shape: torch.Size([32, 8, 1024])\n",
      "BEGIN FORWARD\n",
      "x input shape: torch.Size([32, 1024, 512])\n",
      "x_reshaped shape: torch.Size([32, 1024, 8, 64])\n",
      "values : torch.Size([32, 1024, 8, 64])\n",
      "queries : torch.Size([32, 1024, 8, 128])\n",
      "keys : torch.Size([32, 1024, 8, 128])\n",
      "attention_scores after random projection: torch.Size([32, 8, 1024, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 0, Partition End 128 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 128, Partition End 256 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 256, Partition End 384 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 384, Partition End 512 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 512, Partition End 640 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 640, Partition End 768 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 768, Partition End 896 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 896, Partition End 1024 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "values shape: torch.Size([32, 8, 1024, 64])\n",
      "values.reshape(-1, self.head_dim) shape: torch.Size([262144, 64])\n",
      "self.value_projection(values) shape: torch.Size([262144, 128])\n",
      "projected_values shape: torch.Size([32, 8, 1024, 128])\n",
      "2ND EINSUM\n",
      "out shape: torch.Size([32, 8, 1024])\n",
      "BEGIN FORWARD\n",
      "x input shape: torch.Size([32, 1024, 512])\n",
      "x_reshaped shape: torch.Size([32, 1024, 8, 64])\n",
      "values : torch.Size([32, 1024, 8, 64])\n",
      "queries : torch.Size([32, 1024, 8, 128])\n",
      "keys : torch.Size([32, 1024, 8, 128])\n",
      "attention_scores after random projection: torch.Size([32, 8, 1024, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 0, Partition End 128 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 128, Partition End 256 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 256, Partition End 384 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 384, Partition End 512 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 512, Partition End 640 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 640, Partition End 768 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 768, Partition End 896 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 896, Partition End 1024 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "values shape: torch.Size([32, 8, 1024, 64])\n",
      "values.reshape(-1, self.head_dim) shape: torch.Size([262144, 64])\n",
      "self.value_projection(values) shape: torch.Size([262144, 128])\n",
      "projected_values shape: torch.Size([32, 8, 1024, 128])\n",
      "2ND EINSUM\n",
      "out shape: torch.Size([32, 8, 1024])\n",
      "BEGIN FORWARD\n",
      "x input shape: torch.Size([4, 1024, 512])\n",
      "x_reshaped shape: torch.Size([4, 1024, 8, 64])\n",
      "values : torch.Size([4, 1024, 8, 64])\n",
      "queries : torch.Size([4, 1024, 8, 128])\n",
      "keys : torch.Size([4, 1024, 8, 128])\n",
      "attention_scores after random projection: torch.Size([4, 8, 1024, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([4, 128, 8, 128])\n",
      "Partition Start 0, Partition End 128 , ponder_scores: torch.Size([4, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([4, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([4, 128, 8, 128])\n",
      "queries_part shape: torch.Size([4, 128, 8, 128])\n",
      "C_keys shape: torch.Size([4, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([4, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([4, 128, 8, 128])\n",
      "attention shape: torch.Size([4, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([4, 128, 8, 128])\n",
      "Partition Start 128, Partition End 256 , ponder_scores: torch.Size([4, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([4, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([4, 128, 8, 128])\n",
      "queries_part shape: torch.Size([4, 128, 8, 128])\n",
      "C_keys shape: torch.Size([4, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([4, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([4, 128, 8, 128])\n",
      "attention shape: torch.Size([4, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([4, 128, 8, 128])\n",
      "Partition Start 256, Partition End 384 , ponder_scores: torch.Size([4, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([4, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([4, 128, 8, 128])\n",
      "queries_part shape: torch.Size([4, 128, 8, 128])\n",
      "C_keys shape: torch.Size([4, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([4, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([4, 128, 8, 128])\n",
      "attention shape: torch.Size([4, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([4, 128, 8, 128])\n",
      "Partition Start 384, Partition End 512 , ponder_scores: torch.Size([4, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([4, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([4, 128, 8, 128])\n",
      "queries_part shape: torch.Size([4, 128, 8, 128])\n",
      "C_keys shape: torch.Size([4, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([4, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([4, 128, 8, 128])\n",
      "attention shape: torch.Size([4, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([4, 128, 8, 128])\n",
      "Partition Start 512, Partition End 640 , ponder_scores: torch.Size([4, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([4, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([4, 128, 8, 128])\n",
      "queries_part shape: torch.Size([4, 128, 8, 128])\n",
      "C_keys shape: torch.Size([4, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([4, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([4, 128, 8, 128])\n",
      "attention shape: torch.Size([4, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([4, 128, 8, 128])\n",
      "Partition Start 640, Partition End 768 , ponder_scores: torch.Size([4, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([4, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([4, 128, 8, 128])\n",
      "queries_part shape: torch.Size([4, 128, 8, 128])\n",
      "C_keys shape: torch.Size([4, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([4, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([4, 128, 8, 128])\n",
      "attention shape: torch.Size([4, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([4, 128, 8, 128])\n",
      "Partition Start 768, Partition End 896 , ponder_scores: torch.Size([4, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([4, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([4, 128, 8, 128])\n",
      "queries_part shape: torch.Size([4, 128, 8, 128])\n",
      "C_keys shape: torch.Size([4, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([4, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([4, 128, 8, 128])\n",
      "attention shape: torch.Size([4, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([4, 128, 8, 128])\n",
      "Partition Start 896, Partition End 1024 , ponder_scores: torch.Size([4, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([4, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([4, 128, 8, 128])\n",
      "queries_part shape: torch.Size([4, 128, 8, 128])\n",
      "C_keys shape: torch.Size([4, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([4, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([4, 128, 8, 128])\n",
      "attention shape: torch.Size([4, 128, 8, 128])\n",
      "values shape: torch.Size([4, 8, 1024, 64])\n",
      "values.reshape(-1, self.head_dim) shape: torch.Size([32768, 64])\n",
      "self.value_projection(values) shape: torch.Size([32768, 128])\n",
      "projected_values shape: torch.Size([4, 8, 1024, 128])\n",
      "2ND EINSUM\n",
      "out shape: torch.Size([4, 8, 1024])\n",
      "Epoch: 3, Loss: 2.29541015625\n",
      "BEGIN FORWARD\n",
      "x input shape: torch.Size([32, 1024, 512])\n",
      "x_reshaped shape: torch.Size([32, 1024, 8, 64])\n",
      "values : torch.Size([32, 1024, 8, 64])\n",
      "queries : torch.Size([32, 1024, 8, 128])\n",
      "keys : torch.Size([32, 1024, 8, 128])\n",
      "attention_scores after random projection: torch.Size([32, 8, 1024, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 0, Partition End 128 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 128, Partition End 256 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 256, Partition End 384 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 384, Partition End 512 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 512, Partition End 640 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 640, Partition End 768 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 768, Partition End 896 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 896, Partition End 1024 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "values shape: torch.Size([32, 8, 1024, 64])\n",
      "values.reshape(-1, self.head_dim) shape: torch.Size([262144, 64])\n",
      "self.value_projection(values) shape: torch.Size([262144, 128])\n",
      "projected_values shape: torch.Size([32, 8, 1024, 128])\n",
      "2ND EINSUM\n",
      "out shape: torch.Size([32, 8, 1024])\n",
      "BEGIN FORWARD\n",
      "x input shape: torch.Size([32, 1024, 512])\n",
      "x_reshaped shape: torch.Size([32, 1024, 8, 64])\n",
      "values : torch.Size([32, 1024, 8, 64])\n",
      "queries : torch.Size([32, 1024, 8, 128])\n",
      "keys : torch.Size([32, 1024, 8, 128])\n",
      "attention_scores after random projection: torch.Size([32, 8, 1024, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 0, Partition End 128 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 128, Partition End 256 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 256, Partition End 384 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 384, Partition End 512 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 512, Partition End 640 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 640, Partition End 768 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 768, Partition End 896 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 896, Partition End 1024 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "values shape: torch.Size([32, 8, 1024, 64])\n",
      "values.reshape(-1, self.head_dim) shape: torch.Size([262144, 64])\n",
      "self.value_projection(values) shape: torch.Size([262144, 128])\n",
      "projected_values shape: torch.Size([32, 8, 1024, 128])\n",
      "2ND EINSUM\n",
      "out shape: torch.Size([32, 8, 1024])\n",
      "BEGIN FORWARD\n",
      "x input shape: torch.Size([32, 1024, 512])\n",
      "x_reshaped shape: torch.Size([32, 1024, 8, 64])\n",
      "values : torch.Size([32, 1024, 8, 64])\n",
      "queries : torch.Size([32, 1024, 8, 128])\n",
      "keys : torch.Size([32, 1024, 8, 128])\n",
      "attention_scores after random projection: torch.Size([32, 8, 1024, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 0, Partition End 128 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 128, Partition End 256 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 256, Partition End 384 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 384, Partition End 512 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 512, Partition End 640 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 640, Partition End 768 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 768, Partition End 896 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 896, Partition End 1024 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "values shape: torch.Size([32, 8, 1024, 64])\n",
      "values.reshape(-1, self.head_dim) shape: torch.Size([262144, 64])\n",
      "self.value_projection(values) shape: torch.Size([262144, 128])\n",
      "projected_values shape: torch.Size([32, 8, 1024, 128])\n",
      "2ND EINSUM\n",
      "out shape: torch.Size([32, 8, 1024])\n",
      "BEGIN FORWARD\n",
      "x input shape: torch.Size([4, 1024, 512])\n",
      "x_reshaped shape: torch.Size([4, 1024, 8, 64])\n",
      "values : torch.Size([4, 1024, 8, 64])\n",
      "queries : torch.Size([4, 1024, 8, 128])\n",
      "keys : torch.Size([4, 1024, 8, 128])\n",
      "attention_scores after random projection: torch.Size([4, 8, 1024, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([4, 128, 8, 128])\n",
      "Partition Start 0, Partition End 128 , ponder_scores: torch.Size([4, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([4, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([4, 128, 8, 128])\n",
      "queries_part shape: torch.Size([4, 128, 8, 128])\n",
      "C_keys shape: torch.Size([4, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([4, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([4, 128, 8, 128])\n",
      "attention shape: torch.Size([4, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([4, 128, 8, 128])\n",
      "Partition Start 128, Partition End 256 , ponder_scores: torch.Size([4, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([4, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([4, 128, 8, 128])\n",
      "queries_part shape: torch.Size([4, 128, 8, 128])\n",
      "C_keys shape: torch.Size([4, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([4, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([4, 128, 8, 128])\n",
      "attention shape: torch.Size([4, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([4, 128, 8, 128])\n",
      "Partition Start 256, Partition End 384 , ponder_scores: torch.Size([4, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([4, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([4, 128, 8, 128])\n",
      "queries_part shape: torch.Size([4, 128, 8, 128])\n",
      "C_keys shape: torch.Size([4, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([4, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([4, 128, 8, 128])\n",
      "attention shape: torch.Size([4, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([4, 128, 8, 128])\n",
      "Partition Start 384, Partition End 512 , ponder_scores: torch.Size([4, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([4, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([4, 128, 8, 128])\n",
      "queries_part shape: torch.Size([4, 128, 8, 128])\n",
      "C_keys shape: torch.Size([4, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([4, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([4, 128, 8, 128])\n",
      "attention shape: torch.Size([4, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([4, 128, 8, 128])\n",
      "Partition Start 512, Partition End 640 , ponder_scores: torch.Size([4, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([4, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([4, 128, 8, 128])\n",
      "queries_part shape: torch.Size([4, 128, 8, 128])\n",
      "C_keys shape: torch.Size([4, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([4, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([4, 128, 8, 128])\n",
      "attention shape: torch.Size([4, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([4, 128, 8, 128])\n",
      "Partition Start 640, Partition End 768 , ponder_scores: torch.Size([4, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([4, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([4, 128, 8, 128])\n",
      "queries_part shape: torch.Size([4, 128, 8, 128])\n",
      "C_keys shape: torch.Size([4, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([4, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([4, 128, 8, 128])\n",
      "attention shape: torch.Size([4, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([4, 128, 8, 128])\n",
      "Partition Start 768, Partition End 896 , ponder_scores: torch.Size([4, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([4, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([4, 128, 8, 128])\n",
      "queries_part shape: torch.Size([4, 128, 8, 128])\n",
      "C_keys shape: torch.Size([4, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([4, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([4, 128, 8, 128])\n",
      "attention shape: torch.Size([4, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([4, 128, 8, 128])\n",
      "Partition Start 896, Partition End 1024 , ponder_scores: torch.Size([4, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([4, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([4, 128, 8, 128])\n",
      "queries_part shape: torch.Size([4, 128, 8, 128])\n",
      "C_keys shape: torch.Size([4, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([4, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([4, 128, 8, 128])\n",
      "attention shape: torch.Size([4, 128, 8, 128])\n",
      "values shape: torch.Size([4, 8, 1024, 64])\n",
      "values.reshape(-1, self.head_dim) shape: torch.Size([32768, 64])\n",
      "self.value_projection(values) shape: torch.Size([32768, 128])\n",
      "projected_values shape: torch.Size([4, 8, 1024, 128])\n",
      "2ND EINSUM\n",
      "out shape: torch.Size([4, 8, 1024])\n",
      "Epoch: 4, Loss: 2.33642578125\n",
      "BEGIN FORWARD\n",
      "x input shape: torch.Size([32, 1024, 512])\n",
      "x_reshaped shape: torch.Size([32, 1024, 8, 64])\n",
      "values : torch.Size([32, 1024, 8, 64])\n",
      "queries : torch.Size([32, 1024, 8, 128])\n",
      "keys : torch.Size([32, 1024, 8, 128])\n",
      "attention_scores after random projection: torch.Size([32, 8, 1024, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 0, Partition End 128 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 128, Partition End 256 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 256, Partition End 384 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 384, Partition End 512 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 512, Partition End 640 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 640, Partition End 768 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 768, Partition End 896 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 896, Partition End 1024 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "values shape: torch.Size([32, 8, 1024, 64])\n",
      "values.reshape(-1, self.head_dim) shape: torch.Size([262144, 64])\n",
      "self.value_projection(values) shape: torch.Size([262144, 128])\n",
      "projected_values shape: torch.Size([32, 8, 1024, 128])\n",
      "2ND EINSUM\n",
      "out shape: torch.Size([32, 8, 1024])\n",
      "BEGIN FORWARD\n",
      "x input shape: torch.Size([32, 1024, 512])\n",
      "x_reshaped shape: torch.Size([32, 1024, 8, 64])\n",
      "values : torch.Size([32, 1024, 8, 64])\n",
      "queries : torch.Size([32, 1024, 8, 128])\n",
      "keys : torch.Size([32, 1024, 8, 128])\n",
      "attention_scores after random projection: torch.Size([32, 8, 1024, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 0, Partition End 128 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 128, Partition End 256 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 256, Partition End 384 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 384, Partition End 512 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 512, Partition End 640 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 640, Partition End 768 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 768, Partition End 896 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 896, Partition End 1024 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "values shape: torch.Size([32, 8, 1024, 64])\n",
      "values.reshape(-1, self.head_dim) shape: torch.Size([262144, 64])\n",
      "self.value_projection(values) shape: torch.Size([262144, 128])\n",
      "projected_values shape: torch.Size([32, 8, 1024, 128])\n",
      "2ND EINSUM\n",
      "out shape: torch.Size([32, 8, 1024])\n",
      "BEGIN FORWARD\n",
      "x input shape: torch.Size([32, 1024, 512])\n",
      "x_reshaped shape: torch.Size([32, 1024, 8, 64])\n",
      "values : torch.Size([32, 1024, 8, 64])\n",
      "queries : torch.Size([32, 1024, 8, 128])\n",
      "keys : torch.Size([32, 1024, 8, 128])\n",
      "attention_scores after random projection: torch.Size([32, 8, 1024, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 0, Partition End 128 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 128, Partition End 256 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 256, Partition End 384 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 384, Partition End 512 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 512, Partition End 640 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 640, Partition End 768 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 768, Partition End 896 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 896, Partition End 1024 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "values shape: torch.Size([32, 8, 1024, 64])\n",
      "values.reshape(-1, self.head_dim) shape: torch.Size([262144, 64])\n",
      "self.value_projection(values) shape: torch.Size([262144, 128])\n",
      "projected_values shape: torch.Size([32, 8, 1024, 128])\n",
      "2ND EINSUM\n",
      "out shape: torch.Size([32, 8, 1024])\n",
      "BEGIN FORWARD\n",
      "x input shape: torch.Size([4, 1024, 512])\n",
      "x_reshaped shape: torch.Size([4, 1024, 8, 64])\n",
      "values : torch.Size([4, 1024, 8, 64])\n",
      "queries : torch.Size([4, 1024, 8, 128])\n",
      "keys : torch.Size([4, 1024, 8, 128])\n",
      "attention_scores after random projection: torch.Size([4, 8, 1024, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([4, 128, 8, 128])\n",
      "Partition Start 0, Partition End 128 , ponder_scores: torch.Size([4, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([4, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([4, 128, 8, 128])\n",
      "queries_part shape: torch.Size([4, 128, 8, 128])\n",
      "C_keys shape: torch.Size([4, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([4, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([4, 128, 8, 128])\n",
      "attention shape: torch.Size([4, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([4, 128, 8, 128])\n",
      "Partition Start 128, Partition End 256 , ponder_scores: torch.Size([4, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([4, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([4, 128, 8, 128])\n",
      "queries_part shape: torch.Size([4, 128, 8, 128])\n",
      "C_keys shape: torch.Size([4, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([4, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([4, 128, 8, 128])\n",
      "attention shape: torch.Size([4, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([4, 128, 8, 128])\n",
      "Partition Start 256, Partition End 384 , ponder_scores: torch.Size([4, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([4, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([4, 128, 8, 128])\n",
      "queries_part shape: torch.Size([4, 128, 8, 128])\n",
      "C_keys shape: torch.Size([4, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([4, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([4, 128, 8, 128])\n",
      "attention shape: torch.Size([4, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([4, 128, 8, 128])\n",
      "Partition Start 384, Partition End 512 , ponder_scores: torch.Size([4, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([4, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([4, 128, 8, 128])\n",
      "queries_part shape: torch.Size([4, 128, 8, 128])\n",
      "C_keys shape: torch.Size([4, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([4, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([4, 128, 8, 128])\n",
      "attention shape: torch.Size([4, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([4, 128, 8, 128])\n",
      "Partition Start 512, Partition End 640 , ponder_scores: torch.Size([4, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([4, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([4, 128, 8, 128])\n",
      "queries_part shape: torch.Size([4, 128, 8, 128])\n",
      "C_keys shape: torch.Size([4, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([4, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([4, 128, 8, 128])\n",
      "attention shape: torch.Size([4, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([4, 128, 8, 128])\n",
      "Partition Start 640, Partition End 768 , ponder_scores: torch.Size([4, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([4, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([4, 128, 8, 128])\n",
      "queries_part shape: torch.Size([4, 128, 8, 128])\n",
      "C_keys shape: torch.Size([4, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([4, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([4, 128, 8, 128])\n",
      "attention shape: torch.Size([4, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([4, 128, 8, 128])\n",
      "Partition Start 768, Partition End 896 , ponder_scores: torch.Size([4, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([4, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([4, 128, 8, 128])\n",
      "queries_part shape: torch.Size([4, 128, 8, 128])\n",
      "C_keys shape: torch.Size([4, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([4, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([4, 128, 8, 128])\n",
      "attention shape: torch.Size([4, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([4, 128, 8, 128])\n",
      "Partition Start 896, Partition End 1024 , ponder_scores: torch.Size([4, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([4, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([4, 128, 8, 128])\n",
      "queries_part shape: torch.Size([4, 128, 8, 128])\n",
      "C_keys shape: torch.Size([4, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([4, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([4, 128, 8, 128])\n",
      "attention shape: torch.Size([4, 128, 8, 128])\n",
      "values shape: torch.Size([4, 8, 1024, 64])\n",
      "values.reshape(-1, self.head_dim) shape: torch.Size([32768, 64])\n",
      "self.value_projection(values) shape: torch.Size([32768, 128])\n",
      "projected_values shape: torch.Size([4, 8, 1024, 128])\n",
      "2ND EINSUM\n",
      "out shape: torch.Size([4, 8, 1024])\n",
      "Epoch: 5, Loss: 2.32470703125\n",
      "BEGIN FORWARD\n",
      "x input shape: torch.Size([32, 1024, 512])\n",
      "x_reshaped shape: torch.Size([32, 1024, 8, 64])\n",
      "values : torch.Size([32, 1024, 8, 64])\n",
      "queries : torch.Size([32, 1024, 8, 128])\n",
      "keys : torch.Size([32, 1024, 8, 128])\n",
      "attention_scores after random projection: torch.Size([32, 8, 1024, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 0, Partition End 128 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 128, Partition End 256 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 256, Partition End 384 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 384, Partition End 512 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 512, Partition End 640 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 640, Partition End 768 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 768, Partition End 896 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 896, Partition End 1024 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "values shape: torch.Size([32, 8, 1024, 64])\n",
      "values.reshape(-1, self.head_dim) shape: torch.Size([262144, 64])\n",
      "self.value_projection(values) shape: torch.Size([262144, 128])\n",
      "projected_values shape: torch.Size([32, 8, 1024, 128])\n",
      "2ND EINSUM\n",
      "out shape: torch.Size([32, 8, 1024])\n",
      "BEGIN FORWARD\n",
      "x input shape: torch.Size([32, 1024, 512])\n",
      "x_reshaped shape: torch.Size([32, 1024, 8, 64])\n",
      "values : torch.Size([32, 1024, 8, 64])\n",
      "queries : torch.Size([32, 1024, 8, 128])\n",
      "keys : torch.Size([32, 1024, 8, 128])\n",
      "attention_scores after random projection: torch.Size([32, 8, 1024, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 0, Partition End 128 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 128, Partition End 256 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 256, Partition End 384 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 384, Partition End 512 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 512, Partition End 640 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 640, Partition End 768 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 768, Partition End 896 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 896, Partition End 1024 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "values shape: torch.Size([32, 8, 1024, 64])\n",
      "values.reshape(-1, self.head_dim) shape: torch.Size([262144, 64])\n",
      "self.value_projection(values) shape: torch.Size([262144, 128])\n",
      "projected_values shape: torch.Size([32, 8, 1024, 128])\n",
      "2ND EINSUM\n",
      "out shape: torch.Size([32, 8, 1024])\n",
      "BEGIN FORWARD\n",
      "x input shape: torch.Size([32, 1024, 512])\n",
      "x_reshaped shape: torch.Size([32, 1024, 8, 64])\n",
      "values : torch.Size([32, 1024, 8, 64])\n",
      "queries : torch.Size([32, 1024, 8, 128])\n",
      "keys : torch.Size([32, 1024, 8, 128])\n",
      "attention_scores after random projection: torch.Size([32, 8, 1024, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 0, Partition End 128 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 128, Partition End 256 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 256, Partition End 384 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 384, Partition End 512 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 512, Partition End 640 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 640, Partition End 768 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 768, Partition End 896 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 896, Partition End 1024 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "values shape: torch.Size([32, 8, 1024, 64])\n",
      "values.reshape(-1, self.head_dim) shape: torch.Size([262144, 64])\n",
      "self.value_projection(values) shape: torch.Size([262144, 128])\n",
      "projected_values shape: torch.Size([32, 8, 1024, 128])\n",
      "2ND EINSUM\n",
      "out shape: torch.Size([32, 8, 1024])\n",
      "BEGIN FORWARD\n",
      "x input shape: torch.Size([4, 1024, 512])\n",
      "x_reshaped shape: torch.Size([4, 1024, 8, 64])\n",
      "values : torch.Size([4, 1024, 8, 64])\n",
      "queries : torch.Size([4, 1024, 8, 128])\n",
      "keys : torch.Size([4, 1024, 8, 128])\n",
      "attention_scores after random projection: torch.Size([4, 8, 1024, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([4, 128, 8, 128])\n",
      "Partition Start 0, Partition End 128 , ponder_scores: torch.Size([4, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([4, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([4, 128, 8, 128])\n",
      "queries_part shape: torch.Size([4, 128, 8, 128])\n",
      "C_keys shape: torch.Size([4, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([4, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([4, 128, 8, 128])\n",
      "attention shape: torch.Size([4, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([4, 128, 8, 128])\n",
      "Partition Start 128, Partition End 256 , ponder_scores: torch.Size([4, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([4, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([4, 128, 8, 128])\n",
      "queries_part shape: torch.Size([4, 128, 8, 128])\n",
      "C_keys shape: torch.Size([4, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([4, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([4, 128, 8, 128])\n",
      "attention shape: torch.Size([4, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([4, 128, 8, 128])\n",
      "Partition Start 256, Partition End 384 , ponder_scores: torch.Size([4, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([4, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([4, 128, 8, 128])\n",
      "queries_part shape: torch.Size([4, 128, 8, 128])\n",
      "C_keys shape: torch.Size([4, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([4, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([4, 128, 8, 128])\n",
      "attention shape: torch.Size([4, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([4, 128, 8, 128])\n",
      "Partition Start 384, Partition End 512 , ponder_scores: torch.Size([4, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([4, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([4, 128, 8, 128])\n",
      "queries_part shape: torch.Size([4, 128, 8, 128])\n",
      "C_keys shape: torch.Size([4, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([4, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([4, 128, 8, 128])\n",
      "attention shape: torch.Size([4, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([4, 128, 8, 128])\n",
      "Partition Start 512, Partition End 640 , ponder_scores: torch.Size([4, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([4, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([4, 128, 8, 128])\n",
      "queries_part shape: torch.Size([4, 128, 8, 128])\n",
      "C_keys shape: torch.Size([4, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([4, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([4, 128, 8, 128])\n",
      "attention shape: torch.Size([4, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([4, 128, 8, 128])\n",
      "Partition Start 640, Partition End 768 , ponder_scores: torch.Size([4, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([4, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([4, 128, 8, 128])\n",
      "queries_part shape: torch.Size([4, 128, 8, 128])\n",
      "C_keys shape: torch.Size([4, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([4, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([4, 128, 8, 128])\n",
      "attention shape: torch.Size([4, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([4, 128, 8, 128])\n",
      "Partition Start 768, Partition End 896 , ponder_scores: torch.Size([4, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([4, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([4, 128, 8, 128])\n",
      "queries_part shape: torch.Size([4, 128, 8, 128])\n",
      "C_keys shape: torch.Size([4, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([4, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([4, 128, 8, 128])\n",
      "attention shape: torch.Size([4, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([4, 128, 8, 128])\n",
      "Partition Start 896, Partition End 1024 , ponder_scores: torch.Size([4, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([4, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([4, 128, 8, 128])\n",
      "queries_part shape: torch.Size([4, 128, 8, 128])\n",
      "C_keys shape: torch.Size([4, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([4, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([4, 128, 8, 128])\n",
      "attention shape: torch.Size([4, 128, 8, 128])\n",
      "values shape: torch.Size([4, 8, 1024, 64])\n",
      "values.reshape(-1, self.head_dim) shape: torch.Size([32768, 64])\n",
      "self.value_projection(values) shape: torch.Size([32768, 128])\n",
      "projected_values shape: torch.Size([4, 8, 1024, 128])\n",
      "2ND EINSUM\n",
      "out shape: torch.Size([4, 8, 1024])\n",
      "Epoch: 6, Loss: 2.2890625\n",
      "BEGIN FORWARD\n",
      "x input shape: torch.Size([32, 1024, 512])\n",
      "x_reshaped shape: torch.Size([32, 1024, 8, 64])\n",
      "values : torch.Size([32, 1024, 8, 64])\n",
      "queries : torch.Size([32, 1024, 8, 128])\n",
      "keys : torch.Size([32, 1024, 8, 128])\n",
      "attention_scores after random projection: torch.Size([32, 8, 1024, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 0, Partition End 128 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 128, Partition End 256 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 256, Partition End 384 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 384, Partition End 512 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 512, Partition End 640 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 640, Partition End 768 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 768, Partition End 896 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 896, Partition End 1024 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "values shape: torch.Size([32, 8, 1024, 64])\n",
      "values.reshape(-1, self.head_dim) shape: torch.Size([262144, 64])\n",
      "self.value_projection(values) shape: torch.Size([262144, 128])\n",
      "projected_values shape: torch.Size([32, 8, 1024, 128])\n",
      "2ND EINSUM\n",
      "out shape: torch.Size([32, 8, 1024])\n",
      "BEGIN FORWARD\n",
      "x input shape: torch.Size([32, 1024, 512])\n",
      "x_reshaped shape: torch.Size([32, 1024, 8, 64])\n",
      "values : torch.Size([32, 1024, 8, 64])\n",
      "queries : torch.Size([32, 1024, 8, 128])\n",
      "keys : torch.Size([32, 1024, 8, 128])\n",
      "attention_scores after random projection: torch.Size([32, 8, 1024, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 0, Partition End 128 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 128, Partition End 256 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 256, Partition End 384 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 384, Partition End 512 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 512, Partition End 640 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 640, Partition End 768 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 768, Partition End 896 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 896, Partition End 1024 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "values shape: torch.Size([32, 8, 1024, 64])\n",
      "values.reshape(-1, self.head_dim) shape: torch.Size([262144, 64])\n",
      "self.value_projection(values) shape: torch.Size([262144, 128])\n",
      "projected_values shape: torch.Size([32, 8, 1024, 128])\n",
      "2ND EINSUM\n",
      "out shape: torch.Size([32, 8, 1024])\n",
      "BEGIN FORWARD\n",
      "x input shape: torch.Size([32, 1024, 512])\n",
      "x_reshaped shape: torch.Size([32, 1024, 8, 64])\n",
      "values : torch.Size([32, 1024, 8, 64])\n",
      "queries : torch.Size([32, 1024, 8, 128])\n",
      "keys : torch.Size([32, 1024, 8, 128])\n",
      "attention_scores after random projection: torch.Size([32, 8, 1024, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 0, Partition End 128 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 128, Partition End 256 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 256, Partition End 384 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 384, Partition End 512 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 512, Partition End 640 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 640, Partition End 768 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 768, Partition End 896 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 896, Partition End 1024 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "values shape: torch.Size([32, 8, 1024, 64])\n",
      "values.reshape(-1, self.head_dim) shape: torch.Size([262144, 64])\n",
      "self.value_projection(values) shape: torch.Size([262144, 128])\n",
      "projected_values shape: torch.Size([32, 8, 1024, 128])\n",
      "2ND EINSUM\n",
      "out shape: torch.Size([32, 8, 1024])\n",
      "BEGIN FORWARD\n",
      "x input shape: torch.Size([4, 1024, 512])\n",
      "x_reshaped shape: torch.Size([4, 1024, 8, 64])\n",
      "values : torch.Size([4, 1024, 8, 64])\n",
      "queries : torch.Size([4, 1024, 8, 128])\n",
      "keys : torch.Size([4, 1024, 8, 128])\n",
      "attention_scores after random projection: torch.Size([4, 8, 1024, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([4, 128, 8, 128])\n",
      "Partition Start 0, Partition End 128 , ponder_scores: torch.Size([4, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([4, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([4, 128, 8, 128])\n",
      "queries_part shape: torch.Size([4, 128, 8, 128])\n",
      "C_keys shape: torch.Size([4, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([4, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([4, 128, 8, 128])\n",
      "attention shape: torch.Size([4, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([4, 128, 8, 128])\n",
      "Partition Start 128, Partition End 256 , ponder_scores: torch.Size([4, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([4, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([4, 128, 8, 128])\n",
      "queries_part shape: torch.Size([4, 128, 8, 128])\n",
      "C_keys shape: torch.Size([4, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([4, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([4, 128, 8, 128])\n",
      "attention shape: torch.Size([4, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([4, 128, 8, 128])\n",
      "Partition Start 256, Partition End 384 , ponder_scores: torch.Size([4, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([4, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([4, 128, 8, 128])\n",
      "queries_part shape: torch.Size([4, 128, 8, 128])\n",
      "C_keys shape: torch.Size([4, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([4, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([4, 128, 8, 128])\n",
      "attention shape: torch.Size([4, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([4, 128, 8, 128])\n",
      "Partition Start 384, Partition End 512 , ponder_scores: torch.Size([4, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([4, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([4, 128, 8, 128])\n",
      "queries_part shape: torch.Size([4, 128, 8, 128])\n",
      "C_keys shape: torch.Size([4, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([4, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([4, 128, 8, 128])\n",
      "attention shape: torch.Size([4, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([4, 128, 8, 128])\n",
      "Partition Start 512, Partition End 640 , ponder_scores: torch.Size([4, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([4, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([4, 128, 8, 128])\n",
      "queries_part shape: torch.Size([4, 128, 8, 128])\n",
      "C_keys shape: torch.Size([4, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([4, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([4, 128, 8, 128])\n",
      "attention shape: torch.Size([4, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([4, 128, 8, 128])\n",
      "Partition Start 640, Partition End 768 , ponder_scores: torch.Size([4, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([4, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([4, 128, 8, 128])\n",
      "queries_part shape: torch.Size([4, 128, 8, 128])\n",
      "C_keys shape: torch.Size([4, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([4, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([4, 128, 8, 128])\n",
      "attention shape: torch.Size([4, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([4, 128, 8, 128])\n",
      "Partition Start 768, Partition End 896 , ponder_scores: torch.Size([4, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([4, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([4, 128, 8, 128])\n",
      "queries_part shape: torch.Size([4, 128, 8, 128])\n",
      "C_keys shape: torch.Size([4, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([4, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([4, 128, 8, 128])\n",
      "attention shape: torch.Size([4, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([4, 128, 8, 128])\n",
      "Partition Start 896, Partition End 1024 , ponder_scores: torch.Size([4, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([4, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([4, 128, 8, 128])\n",
      "queries_part shape: torch.Size([4, 128, 8, 128])\n",
      "C_keys shape: torch.Size([4, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([4, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([4, 128, 8, 128])\n",
      "attention shape: torch.Size([4, 128, 8, 128])\n",
      "values shape: torch.Size([4, 8, 1024, 64])\n",
      "values.reshape(-1, self.head_dim) shape: torch.Size([32768, 64])\n",
      "self.value_projection(values) shape: torch.Size([32768, 128])\n",
      "projected_values shape: torch.Size([4, 8, 1024, 128])\n",
      "2ND EINSUM\n",
      "out shape: torch.Size([4, 8, 1024])\n",
      "Epoch: 7, Loss: 2.314453125\n",
      "BEGIN FORWARD\n",
      "x input shape: torch.Size([32, 1024, 512])\n",
      "x_reshaped shape: torch.Size([32, 1024, 8, 64])\n",
      "values : torch.Size([32, 1024, 8, 64])\n",
      "queries : torch.Size([32, 1024, 8, 128])\n",
      "keys : torch.Size([32, 1024, 8, 128])\n",
      "attention_scores after random projection: torch.Size([32, 8, 1024, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 0, Partition End 128 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 128, Partition End 256 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 256, Partition End 384 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 384, Partition End 512 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 512, Partition End 640 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 640, Partition End 768 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 768, Partition End 896 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 896, Partition End 1024 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "values shape: torch.Size([32, 8, 1024, 64])\n",
      "values.reshape(-1, self.head_dim) shape: torch.Size([262144, 64])\n",
      "self.value_projection(values) shape: torch.Size([262144, 128])\n",
      "projected_values shape: torch.Size([32, 8, 1024, 128])\n",
      "2ND EINSUM\n",
      "out shape: torch.Size([32, 8, 1024])\n",
      "BEGIN FORWARD\n",
      "x input shape: torch.Size([32, 1024, 512])\n",
      "x_reshaped shape: torch.Size([32, 1024, 8, 64])\n",
      "values : torch.Size([32, 1024, 8, 64])\n",
      "queries : torch.Size([32, 1024, 8, 128])\n",
      "keys : torch.Size([32, 1024, 8, 128])\n",
      "attention_scores after random projection: torch.Size([32, 8, 1024, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 0, Partition End 128 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 128, Partition End 256 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 256, Partition End 384 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 384, Partition End 512 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 512, Partition End 640 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 640, Partition End 768 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 768, Partition End 896 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 896, Partition End 1024 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "values shape: torch.Size([32, 8, 1024, 64])\n",
      "values.reshape(-1, self.head_dim) shape: torch.Size([262144, 64])\n",
      "self.value_projection(values) shape: torch.Size([262144, 128])\n",
      "projected_values shape: torch.Size([32, 8, 1024, 128])\n",
      "2ND EINSUM\n",
      "out shape: torch.Size([32, 8, 1024])\n",
      "BEGIN FORWARD\n",
      "x input shape: torch.Size([32, 1024, 512])\n",
      "x_reshaped shape: torch.Size([32, 1024, 8, 64])\n",
      "values : torch.Size([32, 1024, 8, 64])\n",
      "queries : torch.Size([32, 1024, 8, 128])\n",
      "keys : torch.Size([32, 1024, 8, 128])\n",
      "attention_scores after random projection: torch.Size([32, 8, 1024, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 0, Partition End 128 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 128, Partition End 256 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 256, Partition End 384 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 384, Partition End 512 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 512, Partition End 640 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 640, Partition End 768 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 768, Partition End 896 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 896, Partition End 1024 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "values shape: torch.Size([32, 8, 1024, 64])\n",
      "values.reshape(-1, self.head_dim) shape: torch.Size([262144, 64])\n",
      "self.value_projection(values) shape: torch.Size([262144, 128])\n",
      "projected_values shape: torch.Size([32, 8, 1024, 128])\n",
      "2ND EINSUM\n",
      "out shape: torch.Size([32, 8, 1024])\n",
      "BEGIN FORWARD\n",
      "x input shape: torch.Size([4, 1024, 512])\n",
      "x_reshaped shape: torch.Size([4, 1024, 8, 64])\n",
      "values : torch.Size([4, 1024, 8, 64])\n",
      "queries : torch.Size([4, 1024, 8, 128])\n",
      "keys : torch.Size([4, 1024, 8, 128])\n",
      "attention_scores after random projection: torch.Size([4, 8, 1024, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([4, 128, 8, 128])\n",
      "Partition Start 0, Partition End 128 , ponder_scores: torch.Size([4, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([4, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([4, 128, 8, 128])\n",
      "queries_part shape: torch.Size([4, 128, 8, 128])\n",
      "C_keys shape: torch.Size([4, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([4, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([4, 128, 8, 128])\n",
      "attention shape: torch.Size([4, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([4, 128, 8, 128])\n",
      "Partition Start 128, Partition End 256 , ponder_scores: torch.Size([4, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([4, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([4, 128, 8, 128])\n",
      "queries_part shape: torch.Size([4, 128, 8, 128])\n",
      "C_keys shape: torch.Size([4, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([4, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([4, 128, 8, 128])\n",
      "attention shape: torch.Size([4, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([4, 128, 8, 128])\n",
      "Partition Start 256, Partition End 384 , ponder_scores: torch.Size([4, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([4, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([4, 128, 8, 128])\n",
      "queries_part shape: torch.Size([4, 128, 8, 128])\n",
      "C_keys shape: torch.Size([4, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([4, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([4, 128, 8, 128])\n",
      "attention shape: torch.Size([4, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([4, 128, 8, 128])\n",
      "Partition Start 384, Partition End 512 , ponder_scores: torch.Size([4, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([4, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([4, 128, 8, 128])\n",
      "queries_part shape: torch.Size([4, 128, 8, 128])\n",
      "C_keys shape: torch.Size([4, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([4, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([4, 128, 8, 128])\n",
      "attention shape: torch.Size([4, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([4, 128, 8, 128])\n",
      "Partition Start 512, Partition End 640 , ponder_scores: torch.Size([4, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([4, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([4, 128, 8, 128])\n",
      "queries_part shape: torch.Size([4, 128, 8, 128])\n",
      "C_keys shape: torch.Size([4, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([4, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([4, 128, 8, 128])\n",
      "attention shape: torch.Size([4, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([4, 128, 8, 128])\n",
      "Partition Start 640, Partition End 768 , ponder_scores: torch.Size([4, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([4, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([4, 128, 8, 128])\n",
      "queries_part shape: torch.Size([4, 128, 8, 128])\n",
      "C_keys shape: torch.Size([4, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([4, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([4, 128, 8, 128])\n",
      "attention shape: torch.Size([4, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([4, 128, 8, 128])\n",
      "Partition Start 768, Partition End 896 , ponder_scores: torch.Size([4, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([4, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([4, 128, 8, 128])\n",
      "queries_part shape: torch.Size([4, 128, 8, 128])\n",
      "C_keys shape: torch.Size([4, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([4, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([4, 128, 8, 128])\n",
      "attention shape: torch.Size([4, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([4, 128, 8, 128])\n",
      "Partition Start 896, Partition End 1024 , ponder_scores: torch.Size([4, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([4, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([4, 128, 8, 128])\n",
      "queries_part shape: torch.Size([4, 128, 8, 128])\n",
      "C_keys shape: torch.Size([4, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([4, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([4, 128, 8, 128])\n",
      "attention shape: torch.Size([4, 128, 8, 128])\n",
      "values shape: torch.Size([4, 8, 1024, 64])\n",
      "values.reshape(-1, self.head_dim) shape: torch.Size([32768, 64])\n",
      "self.value_projection(values) shape: torch.Size([32768, 128])\n",
      "projected_values shape: torch.Size([4, 8, 1024, 128])\n",
      "2ND EINSUM\n",
      "out shape: torch.Size([4, 8, 1024])\n",
      "Epoch: 8, Loss: 2.291015625\n",
      "BEGIN FORWARD\n",
      "x input shape: torch.Size([32, 1024, 512])\n",
      "x_reshaped shape: torch.Size([32, 1024, 8, 64])\n",
      "values : torch.Size([32, 1024, 8, 64])\n",
      "queries : torch.Size([32, 1024, 8, 128])\n",
      "keys : torch.Size([32, 1024, 8, 128])\n",
      "attention_scores after random projection: torch.Size([32, 8, 1024, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 0, Partition End 128 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 128, Partition End 256 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 256, Partition End 384 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 384, Partition End 512 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 512, Partition End 640 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 640, Partition End 768 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 768, Partition End 896 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 896, Partition End 1024 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "values shape: torch.Size([32, 8, 1024, 64])\n",
      "values.reshape(-1, self.head_dim) shape: torch.Size([262144, 64])\n",
      "self.value_projection(values) shape: torch.Size([262144, 128])\n",
      "projected_values shape: torch.Size([32, 8, 1024, 128])\n",
      "2ND EINSUM\n",
      "out shape: torch.Size([32, 8, 1024])\n",
      "BEGIN FORWARD\n",
      "x input shape: torch.Size([32, 1024, 512])\n",
      "x_reshaped shape: torch.Size([32, 1024, 8, 64])\n",
      "values : torch.Size([32, 1024, 8, 64])\n",
      "queries : torch.Size([32, 1024, 8, 128])\n",
      "keys : torch.Size([32, 1024, 8, 128])\n",
      "attention_scores after random projection: torch.Size([32, 8, 1024, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 0, Partition End 128 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 128, Partition End 256 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 256, Partition End 384 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 384, Partition End 512 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 512, Partition End 640 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 640, Partition End 768 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 768, Partition End 896 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 896, Partition End 1024 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "values shape: torch.Size([32, 8, 1024, 64])\n",
      "values.reshape(-1, self.head_dim) shape: torch.Size([262144, 64])\n",
      "self.value_projection(values) shape: torch.Size([262144, 128])\n",
      "projected_values shape: torch.Size([32, 8, 1024, 128])\n",
      "2ND EINSUM\n",
      "out shape: torch.Size([32, 8, 1024])\n",
      "BEGIN FORWARD\n",
      "x input shape: torch.Size([32, 1024, 512])\n",
      "x_reshaped shape: torch.Size([32, 1024, 8, 64])\n",
      "values : torch.Size([32, 1024, 8, 64])\n",
      "queries : torch.Size([32, 1024, 8, 128])\n",
      "keys : torch.Size([32, 1024, 8, 128])\n",
      "attention_scores after random projection: torch.Size([32, 8, 1024, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 0, Partition End 128 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 128, Partition End 256 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 256, Partition End 384 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 384, Partition End 512 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 512, Partition End 640 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 640, Partition End 768 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 768, Partition End 896 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([32, 128, 8, 128])\n",
      "Partition Start 896, Partition End 1024 , ponder_scores: torch.Size([32, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([32, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([32, 128, 8, 128])\n",
      "queries_part shape: torch.Size([32, 128, 8, 128])\n",
      "C_keys shape: torch.Size([32, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([32, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([32, 128, 8, 128])\n",
      "attention shape: torch.Size([32, 128, 8, 128])\n",
      "values shape: torch.Size([32, 8, 1024, 64])\n",
      "values.reshape(-1, self.head_dim) shape: torch.Size([262144, 64])\n",
      "self.value_projection(values) shape: torch.Size([262144, 128])\n",
      "projected_values shape: torch.Size([32, 8, 1024, 128])\n",
      "2ND EINSUM\n",
      "out shape: torch.Size([32, 8, 1024])\n",
      "BEGIN FORWARD\n",
      "x input shape: torch.Size([4, 1024, 512])\n",
      "x_reshaped shape: torch.Size([4, 1024, 8, 64])\n",
      "values : torch.Size([4, 1024, 8, 64])\n",
      "queries : torch.Size([4, 1024, 8, 128])\n",
      "keys : torch.Size([4, 1024, 8, 128])\n",
      "attention_scores after random projection: torch.Size([4, 8, 1024, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([4, 128, 8, 128])\n",
      "Partition Start 0, Partition End 128 , ponder_scores: torch.Size([4, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([4, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([4, 128, 8, 128])\n",
      "queries_part shape: torch.Size([4, 128, 8, 128])\n",
      "C_keys shape: torch.Size([4, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([4, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([4, 128, 8, 128])\n",
      "attention shape: torch.Size([4, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([4, 128, 8, 128])\n",
      "Partition Start 128, Partition End 256 , ponder_scores: torch.Size([4, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([4, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([4, 128, 8, 128])\n",
      "queries_part shape: torch.Size([4, 128, 8, 128])\n",
      "C_keys shape: torch.Size([4, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([4, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([4, 128, 8, 128])\n",
      "attention shape: torch.Size([4, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([4, 128, 8, 128])\n",
      "Partition Start 256, Partition End 384 , ponder_scores: torch.Size([4, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([4, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([4, 128, 8, 128])\n",
      "queries_part shape: torch.Size([4, 128, 8, 128])\n",
      "C_keys shape: torch.Size([4, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([4, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([4, 128, 8, 128])\n",
      "attention shape: torch.Size([4, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([4, 128, 8, 128])\n",
      "Partition Start 384, Partition End 512 , ponder_scores: torch.Size([4, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([4, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([4, 128, 8, 128])\n",
      "queries_part shape: torch.Size([4, 128, 8, 128])\n",
      "C_keys shape: torch.Size([4, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([4, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([4, 128, 8, 128])\n",
      "attention shape: torch.Size([4, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([4, 128, 8, 128])\n",
      "Partition Start 512, Partition End 640 , ponder_scores: torch.Size([4, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([4, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([4, 128, 8, 128])\n",
      "queries_part shape: torch.Size([4, 128, 8, 128])\n",
      "C_keys shape: torch.Size([4, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([4, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([4, 128, 8, 128])\n",
      "attention shape: torch.Size([4, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([4, 128, 8, 128])\n",
      "Partition Start 640, Partition End 768 , ponder_scores: torch.Size([4, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([4, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([4, 128, 8, 128])\n",
      "queries_part shape: torch.Size([4, 128, 8, 128])\n",
      "C_keys shape: torch.Size([4, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([4, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([4, 128, 8, 128])\n",
      "attention shape: torch.Size([4, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([4, 128, 8, 128])\n",
      "Partition Start 768, Partition End 896 , ponder_scores: torch.Size([4, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([4, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([4, 128, 8, 128])\n",
      "queries_part shape: torch.Size([4, 128, 8, 128])\n",
      "C_keys shape: torch.Size([4, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([4, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([4, 128, 8, 128])\n",
      "attention shape: torch.Size([4, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([4, 128, 8, 128])\n",
      "Partition Start 896, Partition End 1024 , ponder_scores: torch.Size([4, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([4, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([4, 128, 8, 128])\n",
      "queries_part shape: torch.Size([4, 128, 8, 128])\n",
      "C_keys shape: torch.Size([4, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([4, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([4, 128, 8, 128])\n",
      "attention shape: torch.Size([4, 128, 8, 128])\n",
      "values shape: torch.Size([4, 8, 1024, 64])\n",
      "values.reshape(-1, self.head_dim) shape: torch.Size([32768, 64])\n",
      "self.value_projection(values) shape: torch.Size([32768, 128])\n",
      "projected_values shape: torch.Size([4, 8, 1024, 128])\n",
      "2ND EINSUM\n",
      "out shape: torch.Size([4, 8, 1024])\n",
      "Epoch: 9, Loss: 2.3408203125\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from torch.optim import Adam\n",
    "\n",
    "\n",
    "\n",
    "def random_projection(matrix, k):\n",
    "    \"\"\"Random projection to reduce dimensionality of matrix to k dimensions.\"\"\"\n",
    "    random_matrix = torch.randn(matrix.size(-1), k, device=matrix.device)\n",
    "    return torch.matmul(matrix, random_matrix)\n",
    "\n",
    "def cur_decomposition(matrix, projection_dim):  # Change 'k' argument\n",
    "    \"\"\"Applies CUR decomposition with C matrix dimension aligned to projection dimension.\"\"\"\n",
    "    batch_size, seq_length, heads, dim = matrix.shape\n",
    "    k = min(projection_dim // 2, dim)  # Use projection dimension to determine 'k'\n",
    "    C = torch.zeros(batch_size, seq_length, heads, k, device=matrix.device)\n",
    "    R = torch.zeros(batch_size, k, heads, dim, device=matrix.device)\n",
    "\n",
    "    for b in range(batch_size):\n",
    "        for h in range(heads):\n",
    "            col_indices = np.random.choice(dim, k, replace=False)\n",
    "            row_indices = np.random.choice(seq_length, k, replace=False)\n",
    "            C[b, :, h] = matrix[b, :, h, col_indices]\n",
    "            R[b, :, h] = matrix[b, row_indices, h]\n",
    "    return C, R\n",
    "\n",
    "class PartitionedLinformerAttentionACT(nn.Module):\n",
    "    def __init__(self, embed_size, heads, sequence_length, projection_dim, partition_size):\n",
    "        super().__init__()\n",
    "        self.embed_size = embed_size\n",
    "        self.heads = heads\n",
    "        self.sequence_length = sequence_length\n",
    "        self.projection_dim = projection_dim\n",
    "        self.partition_size = partition_size\n",
    "        self.head_dim = embed_size // heads\n",
    "\n",
    "        self.values = nn.Linear(self.head_dim, self.head_dim, bias=False)\n",
    "        self.keys = nn.Linear(self.head_dim, self.projection_dim, bias=False)\n",
    "        self.queries = nn.Linear(self.head_dim, self.projection_dim, bias=False)\n",
    "        self.value_projection = nn.Linear(self.head_dim, self.projection_dim//2)  # To project values to match dimensions\n",
    "        self.ponder = nn.Linear(self.partition_size, 1, bias=True)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        print(f\"BEGIN FORWARD\")\n",
    "        print(f\"x input shape: {x.shape}\")\n",
    "        N, seq_length, _ = x.shape\n",
    "        x_reshaped = x.view(N, seq_length, self.heads, self.head_dim)\n",
    "        print(f\"x_reshaped shape: {x_reshaped.shape}\")\n",
    "\n",
    "        values = self.values(x_reshaped)\n",
    "        queries = random_projection(self.queries(x_reshaped), self.projection_dim // 2)\n",
    "        keys = random_projection(self.keys(x_reshaped), self.projection_dim // 2 )\n",
    "        print(\"values :\", values.shape)\n",
    "        print(\"queries :\", queries.shape)\n",
    "        print(\"keys :\", keys.shape)\n",
    "\n",
    "        attention_scores = torch.zeros(N, self.heads, seq_length, self.projection_dim // 2, device=x.device)\n",
    "        print(f\"attention_scores after random projection: {attention_scores.shape}\")\n",
    "\n",
    "        for i in range(0, seq_length, self.partition_size):\n",
    "            print(f\"PARTITION START\")\n",
    "            partition_start = i\n",
    "            partition_end = min(i + self.partition_size, seq_length)\n",
    "            keys_part = keys[:, partition_start:partition_end, :, :]\n",
    "            queries_part = queries[:, partition_start:partition_end, :, :]\n",
    "\n",
    "            C_keys, R_queries = cur_decomposition(keys_part, self.projection_dim)\n",
    "            print(\"C_keys shape before return:\", C_keys.shape)\n",
    "\n",
    "            ponder_scores = torch.zeros(N, self.heads, partition_end - partition_start, 1, device=x.device)\n",
    "            print(f\"Partition Start {i}, Partition End {partition_end} , ponder_scores: {ponder_scores.shape}\")\n",
    "\n",
    "            for h in range(self.heads):\n",
    "                #print(f\"HEADS START\")\n",
    "                head_queries = queries_part[:, :, h, :]\n",
    "                #print(f\"head_queries: {head_queries.shape}\")\n",
    "                head_ponder_scores = self.sigmoid(self.ponder(head_queries))\n",
    "                #print(f\"head_ponder_scores: {head_ponder_scores.shape}\")\n",
    "                ponder_scores[:, h, :, 0] = head_ponder_scores.squeeze(-1)\n",
    "\n",
    "            # Correctly expand ponder_scores without adding an unnecessary dimension\n",
    "            print(\"BEFORE 1ST EINSUM:\")\n",
    "            ponder_scores_permuted = ponder_scores.permute(0, 2, 1, 3)  # Move to [2, 128, 8, 1]\n",
    "            print(\"ponder_scores_permuted shape:\", ponder_scores_permuted.shape) \n",
    "            ponder_scores_broadcastable = ponder_scores_permuted.expand(-1, -1, -1, 128)  # Expand to [2, 128, 8, 128]            print(f\"ponder_scores_broadcastable shape: {ponder_scores_broadcastable.shape}\")\n",
    "            print(\"ponder_scores_broadcastable shape:\", ponder_scores_broadcastable.shape) \n",
    "            print(\"queries_part shape:\", queries_part.shape) \n",
    "            print(\"C_keys shape:\", C_keys.shape)\n",
    "            energy = torch.einsum('bnhd,bnhk->bnhd', queries_part, C_keys)\n",
    "            attention_weights = F.softmax(energy, dim=-1)\n",
    "            print(\"AFTER 1ST EINSUM:\")\n",
    "            print(\"energy shape:\", energy.shape) \n",
    "            print(\"attention_weights shape:\", attention_weights.shape)\n",
    "            attention = attention_weights * ponder_scores_broadcastable\n",
    "            print(\"attention shape:\", attention.shape)\n",
    "            attention_corrected = attention.permute(0, 2, 1, 3)\n",
    "            attention_scores[:, :, partition_start:partition_end, :] = attention_corrected\n",
    "\n",
    "        values = values.permute(0, 2, 1, 3)  # Swap heads and seq_length to bring heads next to head_dim\n",
    "        print(\"values shape:\", values.shape)\n",
    "        values = values.reshape(-1, self.head_dim)  # Flatten to [N*heads*seq_length, head_dim] for linear layer\n",
    "        print(\"values.reshape(-1, self.head_dim) shape:\", values.shape)\n",
    "        projected_values = self.value_projection(values)  # Now [N*heads*seq_length, projection_dim / 2]\n",
    "        print(\"self.value_projection(values) shape:\", projected_values.shape)\n",
    "        projected_values = projected_values.view(N, self.heads, seq_length, self.projection_dim // 2)\n",
    "        print(\"projected_values shape:\", projected_values.shape)\n",
    "\n",
    "        print(f\"2ND EINSUM\")\n",
    "        # Combine attention_scores and projected_values then pass through the final linear layer\n",
    "        out = torch.einsum('bnhp,bnhp->bnh', attention_scores, projected_values)\n",
    "        print(\"out shape:\", out.shape)\n",
    "       \n",
    "        return out\n",
    "\n",
    "'''\n",
    "# Example usage\n",
    "model = PartitionedLinformerAttentionACT(embed_size=512, heads=8, sequence_length=1024, projection_dim=256, partition_size=128)\n",
    "input_tensor = torch.rand(2, model.sequence_length, model.embed_size)\n",
    "output = model(input_tensor)\n",
    "print(output.shape)  \n",
    "'''\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Assuming the input tensor size is [batch_size, sequence_length, embed_size]\n",
    "embed_size = 512  # Size of each word embedding\n",
    "heads = 8  # Number of attention heads\n",
    "sequence_length = 1024  # Length of the input sequence\n",
    "projection_dim = 256  # Dimension to project the input embeddings\n",
    "partition_size = 128  # Size of partitions for processing\n",
    "num_classes = 10\n",
    "# Instantiate the model\n",
    "attention_model  = PartitionedLinformerAttentionACT(embed_size, heads, sequence_length, projection_dim, partition_size)\n",
    "class AttentionClassifier(nn.Module):\n",
    "    def __init__(self, attention_model, num_classes):\n",
    "        super().__init__()\n",
    "        self.attention_model = attention_model\n",
    "        self.global_pool = nn.AdaptiveAvgPool1d(1)  # Global pooling\n",
    "        # Assuming the attention model's output dimensions here; adjust as necessary\n",
    "        projection_dim = attention_model.projection_dim\n",
    "        heads = attention_model.heads\n",
    "        self.classifier = nn.Linear(heads * (projection_dim // 2), num_classes)  # Classifier layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        N, seq_length, _ = x.shape\n",
    "        out = self.attention_model(x)\n",
    "        # Ensure out has dimensions [batch_size, seq_length, num_heads * (projection_dim // 2)]\n",
    "        # You might need to adjust this depending on your attention model's exact output\n",
    "        out = out.permute(0, 2, 1)  # Change shape to [batch_size, sequence_length, num_heads]\n",
    "        out = self.global_pool(out).squeeze(-1)  # Global pooling, resulting in [batch_size, num_heads]\n",
    "        out = out.view(N, -1)  # Flatten\n",
    "        out = self.classifier(out)  # Pass through classifier\n",
    "        return out\n",
    "# Move the model to the appropriate device\n",
    "model = AttentionClassifier(attention_model, num_classes).to(device)\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "# Create a DataLoader with pinned memory\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        # Initialize your data here\n",
    "        pass\n",
    "    def __len__(self):\n",
    "        # Return the size of your dataset\n",
    "        return 100  # Example size\n",
    "    def __getitem__(self, idx):\n",
    "        # Example: Pad the sequence to length 1024 and ensure embed_size is 512\n",
    "        # This is a simplified example; adjust according to your actual data\n",
    "        input_tensor = torch.randn(1024, 512)  # Padded/modeled input to match expected dimensions\n",
    "        target = torch.randint(0, 10, (1,)).item()  # Generate a random class index (0 to 9 for 10 classes)\n",
    "        return input_tensor, target\n",
    "\n",
    "\n",
    "dataset = MyDataset()\n",
    "loader = DataLoader(dataset, batch_size=32, shuffle=True, pin_memory=True)\n",
    "optimizer = Adam(model.parameters(), lr=1e-3)\n",
    "scaler = GradScaler()\n",
    "\n",
    "for epoch in range(10):  # Example: 10 epochs\n",
    "    for inputs, targets in loader:\n",
    "        # Move inputs and targets to the correct device\n",
    "        inputs, targets = inputs.to(device, non_blocking=True), targets.to(device, non_blocking=True)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        with autocast():\n",
    "            # Forward pass through the model\n",
    "            predictions = model(inputs)\n",
    "            \n",
    "            # Calculate loss (assuming classification task and targets are class indices)\n",
    "            loss = nn.functional.cross_entropy(predictions, targets)\n",
    "        \n",
    "        # Backward pass and optimizer step using gradient scaling for mixed precision\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "    print(f\"Epoch: {epoch}, Loss: {loss}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test SPLASH Attention on Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trie built successfully.\n",
      "2749\n",
      "len(wiki_dataset_for_lm): 3\n",
      "Batch 0 input_ids shape: torch.Size([3, 1024]), labels shape: torch.Size([3, 1024])\n",
      "Batch 0 input_ids shape: torch.Size([3, 1024]), labels shape: torch.Size([3, 1024])\n",
      "Batch 0 input_ids shape: torch.Size([3, 1024]), labels shape: torch.Size([3, 1024])\n",
      "Batch 0 input_ids shape: torch.Size([3, 1024]), labels shape: torch.Size([3, 1024])\n",
      "Batch 0 input_ids shape: torch.Size([3, 1024]), labels shape: torch.Size([3, 1024])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from datasets import load_dataset\n",
    "# Test on larger text\n",
    "import re\n",
    "import collections\n",
    "from collections import Counter, defaultdict\n",
    "import json\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from datasets import load_dataset\n",
    "from transformers import BertTokenizer\n",
    "from torch.utils.data import DataLoader\n",
    "import fitz  # PyMuPDF\n",
    "from transformers import BertModel\n",
    "import math\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "from tqdm.notebook import tqdm\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "\n",
    "class SPLASH(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size, heads, sequence_length, projection_dim, partition_size):\n",
    "        super().__init__()\n",
    "        # Embedding layer added\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
    "        # Existing initialization code...\n",
    "        self.embed_size = embed_size\n",
    "        self.heads = heads\n",
    "        self.sequence_length = sequence_length\n",
    "        self.projection_dim = projection_dim\n",
    "        self.partition_size = partition_size\n",
    "        self.head_dim = embed_size // heads\n",
    "\n",
    "        self.values = nn.Linear(self.head_dim, self.head_dim, bias=False)\n",
    "        self.keys = nn.Linear(self.head_dim, self.projection_dim, bias=False)\n",
    "        self.queries = nn.Linear(self.head_dim, self.projection_dim, bias=False)\n",
    "        self.value_projection = nn.Linear(self.head_dim, self.projection_dim//2)  # To project values to match dimensions\n",
    "        self.ponder = nn.Linear(self.partition_size, 1, bias=True)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.final_projection = nn.Linear(self.heads * (self.projection_dim // 2), vocab_size)\n",
    "\n",
    "\n",
    "    def random_projection(self, matrix, k):\n",
    "        \"\"\"Random projection to reduce dimensionality of matrix to k dimensions.\"\"\"\n",
    "        random_matrix = torch.randn(matrix.size(-1), k, device=matrix.device)\n",
    "        return torch.matmul(matrix, random_matrix)\n",
    "\n",
    "    def cur_decomposition(self, matrix, projection_dim):\n",
    "        \"\"\"Applies CUR decomposition with C matrix dimension aligned to projection dimension.\"\"\"\n",
    "        batch_size, seq_length, heads, dim = matrix.shape\n",
    "        k = min(projection_dim // 2, dim)\n",
    "        C = torch.zeros(batch_size, seq_length, heads, k, device=matrix.device)\n",
    "        R = torch.zeros(batch_size, k, heads, dim, device=matrix.device)\n",
    "\n",
    "        for b in range(batch_size):\n",
    "            for h in range(heads):\n",
    "                col_indices = np.random.choice(dim, k, replace=False)\n",
    "                row_indices = np.random.choice(seq_length, k, replace=False)\n",
    "                C[b, :, h] = matrix[b, :, h, col_indices]\n",
    "                R[b, :, h] = matrix[b, row_indices, h]\n",
    "        return C, R\n",
    "\n",
    "    def forward(self, input_ids):\n",
    "        print(f\"BEGIN FORWARD\")\n",
    "        x = self.embedding(input_ids)\n",
    "        print(f\"x input shape: {x.shape}\")\n",
    "        N, seq_length, _ = x.shape\n",
    "        x_reshaped = x.view(N, seq_length, self.heads, self.head_dim)\n",
    "        print(f\"x_reshaped shape: {x_reshaped.shape}\")\n",
    "\n",
    "        values = self.values(x_reshaped)\n",
    "        queries = self.random_projection(self.queries(x_reshaped), self.projection_dim // 2)\n",
    "        keys = self.random_projection(self.keys(x_reshaped), self.projection_dim // 2 )\n",
    "        print(\"values :\", values.shape)\n",
    "        print(\"queries :\", queries.shape)\n",
    "        print(\"keys :\", keys.shape)\n",
    "\n",
    "        attention_scores = torch.zeros(N, self.heads, seq_length, self.projection_dim // 2, device=x.device)\n",
    "        print(f\"attention_scores after random projection: {attention_scores.shape}\")\n",
    "\n",
    "        for i in range(0, seq_length, self.partition_size):\n",
    "            print(f\"PARTITION START\")\n",
    "            partition_start = i\n",
    "            partition_end = min(i + self.partition_size, seq_length)\n",
    "            keys_part = keys[:, partition_start:partition_end, :, :]\n",
    "            queries_part = queries[:, partition_start:partition_end, :, :]\n",
    "\n",
    "            C_keys, R_queries = self.cur_decomposition(keys_part, self.projection_dim)\n",
    "            print(\"C_keys shape before return:\", C_keys.shape)\n",
    "\n",
    "            ponder_scores = torch.zeros(N, self.heads, partition_end - partition_start, 1, device=x.device)\n",
    "            print(f\"Partition Start {i}, Partition End {partition_end} , ponder_scores: {ponder_scores.shape}\")\n",
    "\n",
    "            for h in range(self.heads):\n",
    "                #print(f\"HEADS START\")\n",
    "                head_queries = queries_part[:, :, h, :]\n",
    "                #print(f\"head_queries: {head_queries.shape}\")\n",
    "                head_ponder_scores = self.sigmoid(self.ponder(head_queries))\n",
    "                #print(f\"head_ponder_scores: {head_ponder_scores.shape}\")\n",
    "                ponder_scores[:, h, :, 0] = head_ponder_scores.squeeze(-1)\n",
    "\n",
    "            # Correctly expand ponder_scores without adding an unnecessary dimension\n",
    "            print(\"BEFORE 1ST EINSUM:\")\n",
    "            ponder_scores_permuted = ponder_scores.permute(0, 2, 1, 3)  # Move to [2, 128, 8, 1]\n",
    "            print(\"ponder_scores_permuted shape:\", ponder_scores_permuted.shape) \n",
    "            ponder_scores_broadcastable = ponder_scores_permuted.expand(-1, -1, -1, 128)  # Expand to [2, 128, 8, 128]            \n",
    "            print(\"ponder_scores_broadcastable shape:\", ponder_scores_broadcastable.shape) \n",
    "            print(\"queries_part shape:\", queries_part.shape) \n",
    "            print(\"C_keys shape:\", C_keys.shape)\n",
    "            energy = torch.einsum('bnhd,bnhk->bnhd', queries_part, C_keys)\n",
    "            attention_weights = F.softmax(energy, dim=-1)\n",
    "            print(\"AFTER 1ST EINSUM:\")\n",
    "            print(\"energy shape:\", energy.shape) \n",
    "            print(\"attention_weights shape:\", attention_weights.shape)\n",
    "            attention = attention_weights * ponder_scores_broadcastable\n",
    "            print(\"attention shape:\", attention.shape)\n",
    "            attention_corrected = attention.permute(0, 2, 1, 3)\n",
    "            attention_scores[:, :, partition_start:partition_end, :] = attention_corrected\n",
    "\n",
    "        values = values.permute(0, 2, 1, 3)  # Swap heads and seq_length to bring heads next to head_dim\n",
    "        print(\"values shape:\", values.shape)\n",
    "        values = values.reshape(-1, self.head_dim)  # Flatten to [N*heads*seq_length, head_dim] for linear layer\n",
    "        print(\"values.reshape(-1, self.head_dim) shape:\", values.shape)\n",
    "        projected_values = self.value_projection(values)  # Now [N*heads*seq_length, projection_dim / 2]\n",
    "        print(\"self.value_projection(values) shape:\", projected_values.shape)\n",
    "        projected_values = projected_values.view(N, self.heads, seq_length, self.projection_dim // 2)\n",
    "        print(\"projected_values shape:\", projected_values.shape)\n",
    "\n",
    "        print(f\"2ND EINSUM\")\n",
    "        # Combine attention_scores and projected_values then pass through the final linear layer\n",
    "        '''out = torch.einsum('bnhp,bnhp->bnh', attention_scores, projected_values)\n",
    "        print(\"out shape:\", out.shape)\n",
    "        out = self.final_projection(out.view(-1, self.embed_size))  # Reshape and project\n",
    "        print(f\"out from self.final_projection(out.view(-1, self.embed_size)) : {out.shape}\")\n",
    "        print(f\"Final output: { out.view(-1, vocab_size).shape }\")\n",
    "        return out.view(-1, vocab_size)  # Reshape to [batch_size, sequence_length, vocab_size]'''\n",
    "        # Combine attention_scores and projected_values then pass through the final linear layer\n",
    "        out = torch.einsum('bnhp,bnhp->bnhp', attention_scores, projected_values)\n",
    "        print(\"out shape after einsum:\", out.shape)\n",
    "\n",
    "        # Correct reshaping: Flatten batch and sequence length dimensions, keep the last two dimensions for projection\n",
    "        out = out.reshape(-1, self.heads * (self.projection_dim // 2))\n",
    "        print(\"out reshaped for projection:\", out.shape)\n",
    "\n",
    "        # Ensure the final_projection layer matches the flattened shape expected after reshaping\n",
    "        # Assuming final_projection is defined as nn.Linear(self.heads * (self.projection_dim // 2), vocab_size)\n",
    "        out = self.final_projection(out)\n",
    "        print(f\"out after final_projection:\", out.shape)\n",
    "\n",
    "        # At this point, out should have a shape of [batch_size * sequence_length, vocab_size], ready for loss calculation\n",
    "        return out\n",
    "\n",
    "\n",
    "\n",
    "##################################################\n",
    "# Tokenizer\n",
    "\n",
    "class TrieNode:\n",
    "    def __init__(self):\n",
    "        self.children = {}\n",
    "        self.token_id = None\n",
    "        self.frequency = 0\n",
    "        self.failure_link = None\n",
    "        self.is_end = False  # Add is_end attribute to mark the end of a word\n",
    "        self.token = None  # Add token attribute to store the token associated with the node\n",
    "\n",
    "\n",
    "class Trie:\n",
    "    def __init__(self, unk_token_id=0):\n",
    "        self.root = TrieNode()\n",
    "        self.unk_token_id = unk_token_id\n",
    "\n",
    "    def insert(self, token, token_id, frequency):\n",
    "        node = self.root\n",
    "        for char in token:\n",
    "            if char not in node.children:\n",
    "                node.children[char] = TrieNode()\n",
    "            node = node.children[char]\n",
    "        node.token_id = token_id\n",
    "        node.frequency = frequency\n",
    "\n",
    "    def find_subwords(self, token):\n",
    "        \"\"\"Finds the most probable subwords based on frequency.\"\"\"\n",
    "        node = self.root\n",
    "        best_subwords = []\n",
    "\n",
    "        def dfs(current_node, subword='', collected_subwords=[]):\n",
    "            if current_node.token_id is not None:\n",
    "                # Update to correctly calculate total_frequency based on the structure of collected_subwords\n",
    "                total_frequency = sum(n.frequency for _, _, n in collected_subwords) + current_node.frequency\n",
    "                probability = current_node.frequency / total_frequency if total_frequency else 0\n",
    "                collected_subwords.append((subword, probability, current_node))\n",
    "\n",
    "            for char, next_node in current_node.children.items():\n",
    "                dfs(next_node, subword + char, list(collected_subwords))  # Create a copy of the list to avoid shared state\n",
    "\n",
    "        dfs(node)\n",
    "        best_subwords = sorted(best_subwords, key=lambda x: x[1], reverse=True)\n",
    "        return [subword for subword, _, _ in best_subwords][:5] or [self.unk_token_id]\n",
    "\n",
    "\n",
    "    def compute_failure_links(self):\n",
    "        root = self.root\n",
    "        root.failure_link = root  # Root's failure link points to itself\n",
    "        queue = [root]\n",
    "\n",
    "        while queue:\n",
    "            current_node = queue.pop(0)\n",
    "\n",
    "            for char, child_node in current_node.children.items():\n",
    "                queue.append(child_node)\n",
    "\n",
    "                # Follow failure link to find the longest suffix for the child_node\n",
    "                failure_candidate = current_node.failure_link\n",
    "                while failure_candidate != root and char not in failure_candidate.children:\n",
    "                    failure_candidate = failure_candidate.failure_link\n",
    "                child_node.failure_link = failure_candidate.children.get(char, root)\n",
    "\n",
    "\n",
    "class SimpleSentencePiece:\n",
    "    def __init__(self, model_type=\"bpe\", vocab_size=30522):\n",
    "        self.vocab = {}\n",
    "        self.id_to_subword = {}\n",
    "        self.unk_token = \"[UNK]\"\n",
    "        self.unk_token_id = 0\n",
    "        self.vocab_size = vocab_size\n",
    "        self.model = None if model_type == \"bpe\" else None\n",
    "        self.model_type = model_type\n",
    "\n",
    "    def train(self, text):\n",
    "        if self.model_type == \"bpe\":\n",
    "            self.model = BPE(num_merges=self.vocab_size, unk_token_id=self.unk_token_id)\n",
    "            self.model.train(text)\n",
    "            self.vocab = self.model.vocab\n",
    "            self.id_to_subword = {i: word for word, i in self.vocab.items()}\n",
    "        else:\n",
    "            raise NotImplementedError(f\"Model type {self.model_type} not supported yet.\")\n",
    "\n",
    "    def encode(self, text):\n",
    "        text = self.preprocess_text(text)  # Preprocess text before encoding\n",
    "        if not self.model:\n",
    "            raise ValueError(\"Model has not been trained yet.\")\n",
    "        encoded = self.model.encode(text)\n",
    "        #print(f\"Encoded: {encoded[:10]}\")  # Print first 10 encoded tokens\n",
    "        return encoded\n",
    "\n",
    "    def decode(self, ids):\n",
    "        if not self.id_to_subword:\n",
    "            raise ValueError(\"Vocabulary is empty. Ensure the model is trained first.\")\n",
    "        text = \" \".join([self.id_to_subword.get(id_, self.unk_token) for id_ in ids])\n",
    "        text = text.replace(\" </w>\", \"\").replace(\"</w>\", \" \").strip()\n",
    "        return text\n",
    "\n",
    "    def preprocess_text(self, text):\n",
    "        # Convert text to lowercase to ensure case insensitivity\n",
    "        text = text.lower()\n",
    "        # Optionally, handle punctuation by adding spaces around it for better tokenization\n",
    "        text = re.sub(r'([.,!?()])', r' \\1 ', text)\n",
    "        # Replace multiple spaces with a single space\n",
    "        text = re.sub(r'\\s+', ' ', text)\n",
    "        # Trim leading and trailing spaces\n",
    "        text = text.strip()\n",
    "        return text\n",
    "    \n",
    "    def save_model(self, filepath):\n",
    "        model_data = {\n",
    "            'vocab': self.vocab,\n",
    "            'id_to_subword': self.id_to_subword,\n",
    "            'model_type': self.model_type,\n",
    "            'vocab_size': self.vocab_size,\n",
    "            # Potentially include other relevant attributes\n",
    "        }\n",
    "        # Save the high-level tokenizer settings\n",
    "        with open(filepath, 'w') as f:\n",
    "            json.dump(model_data, f)\n",
    "        \n",
    "        # Now save the BPE model specifically\n",
    "        if self.model_type == \"bpe\" and self.model:\n",
    "            self.model.save_model(filepath + \"_bpe\")\n",
    "\n",
    "    def load_model(self, filepath):\n",
    "        with open(filepath, 'r') as f:\n",
    "            model_data = json.load(f)\n",
    "        \n",
    "        self.vocab = model_data['vocab']\n",
    "        self.id_to_subword = model_data['id_to_subword']\n",
    "        self.model_type = model_data['model_type']\n",
    "        self.vocab_size = model_data['vocab_size']\n",
    "        \n",
    "        # Assuming model_type is still \"bpe\", we now load the BPE model\n",
    "        if self.model_type == \"bpe\":\n",
    "            self.model = BPE(self.vocab_size, self.unk_token_id)\n",
    "            self.model.load_model(filepath + \"_bpe\")\n",
    "\n",
    "class BPE:\n",
    "    def __init__(self, num_merges=100, unk_token_id=0):  # Accept unk_token_id parameter\n",
    "        self.vocab = {}\n",
    "        self.merges = []\n",
    "        self.num_merges = num_merges\n",
    "        self.unk_token_id = unk_token_id  # Store the unknown token ID\n",
    "\n",
    "    def train(self, text):\n",
    "        words = re.findall(r'\\w+|[^\\w\\s]', text, re.UNICODE)\n",
    "        vocab = collections.Counter(words)\n",
    "        vocab = {word + '</w>': count for word, count in vocab.items()}\n",
    "        \n",
    "        for _ in range(self.num_merges):  # Use the num_merges from the instance variable\n",
    "            pairs = self.get_stats(vocab)\n",
    "            if not pairs:\n",
    "                break\n",
    "            best = max(pairs, key=pairs.get)\n",
    "            vocab = self.merge_vocab(best, vocab)\n",
    "            self.merges.append(best)\n",
    "\n",
    "        self.vocab = {word: i for i, word in enumerate(vocab.keys())}\n",
    "\n",
    "    @staticmethod\n",
    "    def get_stats(vocab):\n",
    "        pairs = collections.defaultdict(int)\n",
    "        for word, freq in vocab.items():\n",
    "            symbols = word.split()\n",
    "            for i in range(len(symbols)-1):\n",
    "                pairs[symbols[i], symbols[i+1]] += freq\n",
    "        return pairs\n",
    "\n",
    "    @staticmethod\n",
    "    def merge_vocab(pair, vocab):\n",
    "        v_out = {}\n",
    "        bigram = re.escape(' '.join(pair))\n",
    "        p = re.compile(r'(?<!\\S)' + bigram + r'(?!\\S)')\n",
    "        for word in vocab:\n",
    "            w_out = p.sub(''.join(pair), word)\n",
    "            v_out[w_out] = vocab[word]\n",
    "        return v_out\n",
    "\n",
    "    def encode(self, text):\n",
    "        \"\"\"Encode text into subwords using learned BPE merges.\"\"\"\n",
    "        encoded_tokens = []\n",
    "        for word in re.findall(r'\\w+|[^\\w\\s]', text, re.UNICODE):\n",
    "            word += '</w>'\n",
    "            subwords = [word]  # Start with the entire word as one subword\n",
    "            for merge in self.merges:\n",
    "                new_subwords = []\n",
    "                for subword in subwords:\n",
    "                    # If the merge is in subword, split it; otherwise, keep it as is\n",
    "                    if ' '.join(merge) in subword:\n",
    "                        new_subwords.extend(subword.replace(' '.join(merge), ''.join(merge)).split(' '))\n",
    "                    else:\n",
    "                        new_subwords.append(subword)\n",
    "                subwords = new_subwords\n",
    "            encoded_tokens.extend(subwords)\n",
    "        return [self.vocab.get(token, self.unk_token_id) for token in encoded_tokens]\n",
    "    \n",
    "        # New method to save trained model\n",
    "    def save_model(self, filepath):\n",
    "        bpe_data = {\n",
    "            'merges': self.merges,\n",
    "            'vocab': self.vocab,\n",
    "            'num_merges': self.num_merges,\n",
    "            # Include other attributes as needed\n",
    "        }\n",
    "        with open(filepath, 'w') as f:\n",
    "            json.dump(bpe_data, f)\n",
    "\n",
    "    def load_model(self, filepath):\n",
    "        with open(filepath, 'r') as f:\n",
    "            bpe_data = json.load(f)\n",
    "        \n",
    "        self.merges = bpe_data['merges']\n",
    "        self.vocab = bpe_data['vocab']\n",
    "        self.num_merges = bpe_data['num_merges']\n",
    "\n",
    "\n",
    "class WordPiece:\n",
    "    def __init__(self, vocab, unk_token_id=0, unk_token=\"[UNK]\"):\n",
    "        self.vocab = vocab\n",
    "        self.unk_token_id = unk_token_id\n",
    "        self.unk_token = unk_token  # Define the unknown token\n",
    "        self.root = self.build_trie(vocab)\n",
    "        self.id_to_token = {id_: token for token, id_ in vocab.items()}  # Inverse mapping\n",
    "        self.compute_failure_links(self.root)\n",
    "        print(\"Trie built successfully.\")\n",
    "\n",
    "    def convert_ids_to_tokens(self, ids):\n",
    "        \"\"\"\n",
    "        Convert a list of token ids back to their string token representations.\n",
    "        \"\"\"\n",
    "        return [self.id_to_token.get(id_, self.unk_token) for id_ in ids]\n",
    "\n",
    "    # Add debug prints to build_trie to confirm structure\n",
    "    def build_trie(self, vocab):\n",
    "        root = TrieNode()\n",
    "        for token in vocab:\n",
    "            node = root\n",
    "            for char in token:\n",
    "                if char not in node.children:\n",
    "                    node.children[char] = TrieNode()\n",
    "                node = node.children[char]\n",
    "            node.is_end = True\n",
    "            node.token = token\n",
    "        #print(\"Trie Construction Completed Successfully\")\n",
    "        return root\n",
    "\n",
    "\n",
    "    def compute_failure_links(self, root):\n",
    "        queue = [root]\n",
    "        while queue:\n",
    "            current_node = queue.pop(0)\n",
    "            for char, child_node in current_node.children.items():\n",
    "                failure_node = current_node.failure_link\n",
    "                while failure_node and char not in failure_node.children:\n",
    "                    failure_node = failure_node.failure_link\n",
    "                child_node.failure_link = failure_node.children[char] if failure_node else root\n",
    "                queue.append(child_node)\n",
    "\n",
    "    # Improved debug prints in tokenize method\n",
    "                \n",
    "    def tokenize(self, text):\n",
    "        # Preprocess input text\n",
    "        text = self.preprocess_text(text)\n",
    "        node = self.root\n",
    "        token_ids = []  # Will store token IDs instead of tokens\n",
    "        i = 0\n",
    "\n",
    "        while i < len(text):\n",
    "            char = text[i]\n",
    "            if char == ' ':\n",
    "                node = self.root\n",
    "                i += 1\n",
    "                continue\n",
    "\n",
    "            if char not in node.children:\n",
    "                if node != self.root and node.token is not None:\n",
    "                    # Convert found token to its ID\n",
    "                    token_id = self.vocab.get(node.token, self.unk_token_id)\n",
    "                    token_ids.append(token_id)\n",
    "                    node = self.root  # Reset to root\n",
    "                    continue\n",
    "                else:\n",
    "                    # Append unknown token ID\n",
    "                    token_ids.append(self.unk_token_id)\n",
    "                    i += 1\n",
    "                    continue\n",
    "\n",
    "            node = node.children[char]\n",
    "            if node.is_end:\n",
    "                if i + 1 == len(text) or text[i + 1] == ' ':\n",
    "                    # Convert found token to its ID\n",
    "                    token_id = self.vocab.get(node.token, self.unk_token_id)\n",
    "                    token_ids.append(token_id)\n",
    "                    node = self.root\n",
    "\n",
    "            i += 1\n",
    "\n",
    "        #print(f\"Token IDs: {token_ids[:10]}\")\n",
    "        return token_ids\n",
    "\n",
    "    def preprocess_text(self, text):\n",
    "        # Convert text to lowercase to ensure case insensitivity\n",
    "        text = text.lower()\n",
    "\n",
    "        # Optionally, handle punctuation by adding spaces around it for better tokenization\n",
    "        # This depends on how your vocabulary handles punctuation\n",
    "        text = re.sub(r'([.,!?()])', r' \\1 ', text)\n",
    "\n",
    "        # Replace multiple spaces with a single space\n",
    "        text = re.sub(r'\\s+', ' ', text)\n",
    "\n",
    "        # Trim leading and trailing spaces\n",
    "        text = text.strip()\n",
    "\n",
    "        return text\n",
    "\n",
    "\n",
    "def load_corpus(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        texts = [line.strip() for line in file.readlines()]\n",
    "    return texts\n",
    "\n",
    "texts = load_corpus(\"D:\\\\EXPERT_WEIGHTS\\\\sample.txt\")\n",
    "#texts = load_corpus(\"/content/drive/MyDrive/EXPERT_STUFF/sample.txt\")\n",
    "# texts = load_corpus(\"C:/Users/robbi/Expert/sample.txt\")\n",
    "num_merges = 100\n",
    "def adapt_vocab_for_wordpiece(ssp_vocab):\n",
    "    adapted_vocab = {}\n",
    "    for token, id_or_freq in ssp_vocab.items():\n",
    "        if not token.startswith(\" \") and not token.endswith(\"</w>\"):\n",
    "            adapted_token = \"##\" + token.replace(\"</w>\", \"\")\n",
    "        else:\n",
    "            adapted_token = token.replace(\"</w>\", \"\")\n",
    "        adapted_vocab[adapted_token] = id_or_freq\n",
    "    return adapted_vocab\n",
    "\n",
    "# Initialize and train the SimpleSentencePiece model with BPE\n",
    "ssp = SimpleSentencePiece(model_type=\"bpe\", vocab_size=30522)\n",
    "# Assume `texts` is a list of text to train the tokenizer\n",
    "ssp.train('\\n'.join(texts))\n",
    "wordpiece_vocab = adapt_vocab_for_wordpiece(ssp.vocab)\n",
    "# Debugging step to ensure vocabulary completeness\n",
    "def debug_vocab(adapted_vocab):\n",
    "    print(\"Sample Vocabulary Check:\")\n",
    "    # Iterate over the first 10 key-value pairs in the adapted vocabulary\n",
    "    for i, (token, id_or_freq) in enumerate(adapted_vocab.items()):\n",
    "        print(f\"{token}: {id_or_freq}\")\n",
    "        if i >= 9:  # Stop after printing 10 entries\n",
    "            break\n",
    "    # Specifically check for subtokens if your tokenizer expects them\n",
    "    subtokens = [token for token in adapted_vocab.keys() if token.startswith(\"##\")]\n",
    "    print(f\"Found {len(subtokens)} subtokens in vocabulary.\")\n",
    "\n",
    "# Ensure wordpiece_vocab is a list of vocabulary tokens\n",
    "# debug_vocab(wordpiece_vocab)  # Call this after initializing wordpiece_vocab\n",
    "\n",
    "# Initialize WordPiece with the adapted vocabulary\n",
    "wordpiece_tokenizer = WordPiece(wordpiece_vocab, unk_token_id=0, unk_token=\"[UNK]\")\n",
    "\n",
    "class WikiTextDatasetForLM(Dataset):\n",
    "    def __init__(self, texts, tokenizer, sequence_length):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.sequence_length = sequence_length\n",
    "        self.inputs, self.labels = self.process_texts(texts)\n",
    "        \n",
    "    def process_texts(self, texts):\n",
    "        inputs, labels = [], []\n",
    "        for text in texts:\n",
    "            token_ids = self.tokenizer.tokenize(text)\n",
    "            for i in range(0, len(token_ids) - self.sequence_length, self.sequence_length):\n",
    "                # Create sequences of `sequence_length` for inputs\n",
    "                inputs.append(token_ids[i:i+self.sequence_length])\n",
    "                # Shift by one for the labels to predict the next token\n",
    "                labels.append(token_ids[i+1:i+self.sequence_length+1])\n",
    "        return torch.tensor(inputs, dtype=torch.long), torch.tensor(labels, dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.inputs[idx], self.labels[idx]\n",
    "\n",
    "# Assuming vocab_size is determined by your tokenizer's vocabulary size\n",
    "vocab_size = len(wordpiece_tokenizer.vocab)  # Adjust this to match your tokenizer's vocab size method\n",
    "print(vocab_size)\n",
    "# Define other parameters for SPLASH model instantiation\n",
    "embed_size = 512  # Embedding size\n",
    "heads = 8  # Number of attention heads\n",
    "sequence_length = 1024  # Input sequence length\n",
    "projection_dim = 256  # Dimension for projections inside SPLASH\n",
    "partition_size = 128  # Size of partitions for SPLASH processing\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Instantiate SPLASH Model\n",
    "splash_model = SPLASH(vocab_size=vocab_size, embed_size=embed_size, heads=heads, \n",
    "                      sequence_length=sequence_length, projection_dim=projection_dim, \n",
    "                      partition_size=partition_size).to(device)\n",
    "\n",
    "# Load Wikipedia dataset and preprocess\n",
    "dataset = load_dataset(\"wikitext\", \"wikitext-2-v1\", split=\"train\")\n",
    "batch_size = 32  # Adjust based on your hardware capabilities\n",
    "num_epochs  = 5\n",
    "loss_function = nn.CrossEntropyLoss()  # Example, adjust as needed\n",
    "optimizer = torch.optim.Adam(splash_model.parameters(), lr=1e-4)\n",
    "# Extract texts from the dataset\n",
    "texts = dataset['text']\n",
    "\n",
    "# Initialize the dataset for language modeling\n",
    "wiki_dataset_for_lm = WikiTextDatasetForLM(texts, wordpiece_tokenizer, sequence_length=1024)\n",
    "print(f\"len(wiki_dataset_for_lm): {len(wiki_dataset_for_lm)}\")\n",
    "\n",
    "# DataLoader\n",
    "data_loader = DataLoader(wiki_dataset_for_lm, batch_size=32, shuffle=True)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (input_ids, labels) in enumerate(data_loader):\n",
    "        print(f\"Batch {i} input_ids shape: {input_ids.shape}, labels shape: {labels.shape}\")\n",
    "        if i > 5:  # Just to limit output for debugging\n",
    "            break\n",
    "\n",
    "    '''for input_ids, labels in data_loader:\n",
    "        input_ids, labels = input_ids.to(device), labels.to(device)\n",
    "        print(f\"input_ids: {input_ids.shape}\")\n",
    "        print(f\"labels: {labels.shape}\")\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = splash_model(input_ids)\n",
    "\n",
    "        # Flatten the output and label tensors for use with CrossEntropyLoss\n",
    "        outputs_flat = outputs.view(-1, outputs.size(-1))\n",
    "        labels_flat = labels.view(-1)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = loss_function(outputs_flat, labels_flat)\n",
    "        \n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}, Loss: {loss.item()}\")'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trie built successfully.\n",
      "2749\n",
      "len(wiki_dataset_for_lm): 3\n",
      "Batch 0 input_ids shape: torch.Size([3, 1024]), labels shape: torch.Size([3, 1024])\n",
      "input_ids: torch.Size([3, 1024])\n",
      "labels: torch.Size([3, 1024])\n",
      "BEGIN FORWARD\n",
      "x input shape: torch.Size([3, 1024, 512])\n",
      "x_reshaped shape: torch.Size([3, 1024, 8, 64])\n",
      "values : torch.Size([3, 1024, 8, 64])\n",
      "queries : torch.Size([3, 1024, 8, 128])\n",
      "keys : torch.Size([3, 1024, 8, 128])\n",
      "attention_scores after random projection: torch.Size([3, 8, 1024, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([3, 128, 8, 128])\n",
      "Partition Start 0, Partition End 128 , ponder_scores: torch.Size([3, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([3, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([3, 128, 8, 128])\n",
      "queries_part shape: torch.Size([3, 128, 8, 128])\n",
      "C_keys shape: torch.Size([3, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([3, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([3, 128, 8, 128])\n",
      "attention shape: torch.Size([3, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([3, 128, 8, 128])\n",
      "Partition Start 128, Partition End 256 , ponder_scores: torch.Size([3, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([3, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([3, 128, 8, 128])\n",
      "queries_part shape: torch.Size([3, 128, 8, 128])\n",
      "C_keys shape: torch.Size([3, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([3, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([3, 128, 8, 128])\n",
      "attention shape: torch.Size([3, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([3, 128, 8, 128])\n",
      "Partition Start 256, Partition End 384 , ponder_scores: torch.Size([3, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([3, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([3, 128, 8, 128])\n",
      "queries_part shape: torch.Size([3, 128, 8, 128])\n",
      "C_keys shape: torch.Size([3, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([3, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([3, 128, 8, 128])\n",
      "attention shape: torch.Size([3, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([3, 128, 8, 128])\n",
      "Partition Start 384, Partition End 512 , ponder_scores: torch.Size([3, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([3, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([3, 128, 8, 128])\n",
      "queries_part shape: torch.Size([3, 128, 8, 128])\n",
      "C_keys shape: torch.Size([3, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([3, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([3, 128, 8, 128])\n",
      "attention shape: torch.Size([3, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([3, 128, 8, 128])\n",
      "Partition Start 512, Partition End 640 , ponder_scores: torch.Size([3, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([3, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([3, 128, 8, 128])\n",
      "queries_part shape: torch.Size([3, 128, 8, 128])\n",
      "C_keys shape: torch.Size([3, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([3, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([3, 128, 8, 128])\n",
      "attention shape: torch.Size([3, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([3, 128, 8, 128])\n",
      "Partition Start 640, Partition End 768 , ponder_scores: torch.Size([3, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([3, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([3, 128, 8, 128])\n",
      "queries_part shape: torch.Size([3, 128, 8, 128])\n",
      "C_keys shape: torch.Size([3, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([3, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([3, 128, 8, 128])\n",
      "attention shape: torch.Size([3, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([3, 128, 8, 128])\n",
      "Partition Start 768, Partition End 896 , ponder_scores: torch.Size([3, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([3, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([3, 128, 8, 128])\n",
      "queries_part shape: torch.Size([3, 128, 8, 128])\n",
      "C_keys shape: torch.Size([3, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([3, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([3, 128, 8, 128])\n",
      "attention shape: torch.Size([3, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([3, 128, 8, 128])\n",
      "Partition Start 896, Partition End 1024 , ponder_scores: torch.Size([3, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([3, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([3, 128, 8, 128])\n",
      "queries_part shape: torch.Size([3, 128, 8, 128])\n",
      "C_keys shape: torch.Size([3, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([3, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([3, 128, 8, 128])\n",
      "attention shape: torch.Size([3, 128, 8, 128])\n",
      "values shape: torch.Size([3, 8, 1024, 64])\n",
      "values.reshape(-1, self.head_dim) shape: torch.Size([24576, 64])\n",
      "self.value_projection(values) shape: torch.Size([24576, 128])\n",
      "projected_values shape: torch.Size([3, 8, 1024, 128])\n",
      "2ND EINSUM\n",
      "out shape after einsum: torch.Size([3, 8, 1024, 128])\n",
      "out reshaped for projection: torch.Size([3072, 1024])\n",
      "out after final_projection: torch.Size([3072, 2749])\n",
      "Epoch 1, Loss: 7.9223809242248535\n",
      "Batch 0 input_ids shape: torch.Size([3, 1024]), labels shape: torch.Size([3, 1024])\n",
      "input_ids: torch.Size([3, 1024])\n",
      "labels: torch.Size([3, 1024])\n",
      "BEGIN FORWARD\n",
      "x input shape: torch.Size([3, 1024, 512])\n",
      "x_reshaped shape: torch.Size([3, 1024, 8, 64])\n",
      "values : torch.Size([3, 1024, 8, 64])\n",
      "queries : torch.Size([3, 1024, 8, 128])\n",
      "keys : torch.Size([3, 1024, 8, 128])\n",
      "attention_scores after random projection: torch.Size([3, 8, 1024, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([3, 128, 8, 128])\n",
      "Partition Start 0, Partition End 128 , ponder_scores: torch.Size([3, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([3, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([3, 128, 8, 128])\n",
      "queries_part shape: torch.Size([3, 128, 8, 128])\n",
      "C_keys shape: torch.Size([3, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([3, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([3, 128, 8, 128])\n",
      "attention shape: torch.Size([3, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([3, 128, 8, 128])\n",
      "Partition Start 128, Partition End 256 , ponder_scores: torch.Size([3, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([3, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([3, 128, 8, 128])\n",
      "queries_part shape: torch.Size([3, 128, 8, 128])\n",
      "C_keys shape: torch.Size([3, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([3, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([3, 128, 8, 128])\n",
      "attention shape: torch.Size([3, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([3, 128, 8, 128])\n",
      "Partition Start 256, Partition End 384 , ponder_scores: torch.Size([3, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([3, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([3, 128, 8, 128])\n",
      "queries_part shape: torch.Size([3, 128, 8, 128])\n",
      "C_keys shape: torch.Size([3, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([3, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([3, 128, 8, 128])\n",
      "attention shape: torch.Size([3, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([3, 128, 8, 128])\n",
      "Partition Start 384, Partition End 512 , ponder_scores: torch.Size([3, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([3, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([3, 128, 8, 128])\n",
      "queries_part shape: torch.Size([3, 128, 8, 128])\n",
      "C_keys shape: torch.Size([3, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([3, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([3, 128, 8, 128])\n",
      "attention shape: torch.Size([3, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([3, 128, 8, 128])\n",
      "Partition Start 512, Partition End 640 , ponder_scores: torch.Size([3, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([3, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([3, 128, 8, 128])\n",
      "queries_part shape: torch.Size([3, 128, 8, 128])\n",
      "C_keys shape: torch.Size([3, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([3, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([3, 128, 8, 128])\n",
      "attention shape: torch.Size([3, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([3, 128, 8, 128])\n",
      "Partition Start 640, Partition End 768 , ponder_scores: torch.Size([3, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([3, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([3, 128, 8, 128])\n",
      "queries_part shape: torch.Size([3, 128, 8, 128])\n",
      "C_keys shape: torch.Size([3, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([3, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([3, 128, 8, 128])\n",
      "attention shape: torch.Size([3, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([3, 128, 8, 128])\n",
      "Partition Start 768, Partition End 896 , ponder_scores: torch.Size([3, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([3, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([3, 128, 8, 128])\n",
      "queries_part shape: torch.Size([3, 128, 8, 128])\n",
      "C_keys shape: torch.Size([3, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([3, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([3, 128, 8, 128])\n",
      "attention shape: torch.Size([3, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([3, 128, 8, 128])\n",
      "Partition Start 896, Partition End 1024 , ponder_scores: torch.Size([3, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([3, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([3, 128, 8, 128])\n",
      "queries_part shape: torch.Size([3, 128, 8, 128])\n",
      "C_keys shape: torch.Size([3, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([3, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([3, 128, 8, 128])\n",
      "attention shape: torch.Size([3, 128, 8, 128])\n",
      "values shape: torch.Size([3, 8, 1024, 64])\n",
      "values.reshape(-1, self.head_dim) shape: torch.Size([24576, 64])\n",
      "self.value_projection(values) shape: torch.Size([24576, 128])\n",
      "projected_values shape: torch.Size([3, 8, 1024, 128])\n",
      "2ND EINSUM\n",
      "out shape after einsum: torch.Size([3, 8, 1024, 128])\n",
      "out reshaped for projection: torch.Size([3072, 1024])\n",
      "out after final_projection: torch.Size([3072, 2749])\n",
      "Epoch 2, Loss: 7.922674179077148\n",
      "Batch 0 input_ids shape: torch.Size([3, 1024]), labels shape: torch.Size([3, 1024])\n",
      "input_ids: torch.Size([3, 1024])\n",
      "labels: torch.Size([3, 1024])\n",
      "BEGIN FORWARD\n",
      "x input shape: torch.Size([3, 1024, 512])\n",
      "x_reshaped shape: torch.Size([3, 1024, 8, 64])\n",
      "values : torch.Size([3, 1024, 8, 64])\n",
      "queries : torch.Size([3, 1024, 8, 128])\n",
      "keys : torch.Size([3, 1024, 8, 128])\n",
      "attention_scores after random projection: torch.Size([3, 8, 1024, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([3, 128, 8, 128])\n",
      "Partition Start 0, Partition End 128 , ponder_scores: torch.Size([3, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([3, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([3, 128, 8, 128])\n",
      "queries_part shape: torch.Size([3, 128, 8, 128])\n",
      "C_keys shape: torch.Size([3, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([3, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([3, 128, 8, 128])\n",
      "attention shape: torch.Size([3, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([3, 128, 8, 128])\n",
      "Partition Start 128, Partition End 256 , ponder_scores: torch.Size([3, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([3, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([3, 128, 8, 128])\n",
      "queries_part shape: torch.Size([3, 128, 8, 128])\n",
      "C_keys shape: torch.Size([3, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([3, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([3, 128, 8, 128])\n",
      "attention shape: torch.Size([3, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([3, 128, 8, 128])\n",
      "Partition Start 256, Partition End 384 , ponder_scores: torch.Size([3, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([3, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([3, 128, 8, 128])\n",
      "queries_part shape: torch.Size([3, 128, 8, 128])\n",
      "C_keys shape: torch.Size([3, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([3, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([3, 128, 8, 128])\n",
      "attention shape: torch.Size([3, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([3, 128, 8, 128])\n",
      "Partition Start 384, Partition End 512 , ponder_scores: torch.Size([3, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([3, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([3, 128, 8, 128])\n",
      "queries_part shape: torch.Size([3, 128, 8, 128])\n",
      "C_keys shape: torch.Size([3, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([3, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([3, 128, 8, 128])\n",
      "attention shape: torch.Size([3, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([3, 128, 8, 128])\n",
      "Partition Start 512, Partition End 640 , ponder_scores: torch.Size([3, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([3, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([3, 128, 8, 128])\n",
      "queries_part shape: torch.Size([3, 128, 8, 128])\n",
      "C_keys shape: torch.Size([3, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([3, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([3, 128, 8, 128])\n",
      "attention shape: torch.Size([3, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([3, 128, 8, 128])\n",
      "Partition Start 640, Partition End 768 , ponder_scores: torch.Size([3, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([3, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([3, 128, 8, 128])\n",
      "queries_part shape: torch.Size([3, 128, 8, 128])\n",
      "C_keys shape: torch.Size([3, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([3, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([3, 128, 8, 128])\n",
      "attention shape: torch.Size([3, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([3, 128, 8, 128])\n",
      "Partition Start 768, Partition End 896 , ponder_scores: torch.Size([3, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([3, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([3, 128, 8, 128])\n",
      "queries_part shape: torch.Size([3, 128, 8, 128])\n",
      "C_keys shape: torch.Size([3, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([3, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([3, 128, 8, 128])\n",
      "attention shape: torch.Size([3, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([3, 128, 8, 128])\n",
      "Partition Start 896, Partition End 1024 , ponder_scores: torch.Size([3, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([3, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([3, 128, 8, 128])\n",
      "queries_part shape: torch.Size([3, 128, 8, 128])\n",
      "C_keys shape: torch.Size([3, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([3, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([3, 128, 8, 128])\n",
      "attention shape: torch.Size([3, 128, 8, 128])\n",
      "values shape: torch.Size([3, 8, 1024, 64])\n",
      "values.reshape(-1, self.head_dim) shape: torch.Size([24576, 64])\n",
      "self.value_projection(values) shape: torch.Size([24576, 128])\n",
      "projected_values shape: torch.Size([3, 8, 1024, 128])\n",
      "2ND EINSUM\n",
      "out shape after einsum: torch.Size([3, 8, 1024, 128])\n",
      "out reshaped for projection: torch.Size([3072, 1024])\n",
      "out after final_projection: torch.Size([3072, 2749])\n",
      "Epoch 3, Loss: 7.922715663909912\n",
      "Batch 0 input_ids shape: torch.Size([3, 1024]), labels shape: torch.Size([3, 1024])\n",
      "input_ids: torch.Size([3, 1024])\n",
      "labels: torch.Size([3, 1024])\n",
      "BEGIN FORWARD\n",
      "x input shape: torch.Size([3, 1024, 512])\n",
      "x_reshaped shape: torch.Size([3, 1024, 8, 64])\n",
      "values : torch.Size([3, 1024, 8, 64])\n",
      "queries : torch.Size([3, 1024, 8, 128])\n",
      "keys : torch.Size([3, 1024, 8, 128])\n",
      "attention_scores after random projection: torch.Size([3, 8, 1024, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([3, 128, 8, 128])\n",
      "Partition Start 0, Partition End 128 , ponder_scores: torch.Size([3, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([3, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([3, 128, 8, 128])\n",
      "queries_part shape: torch.Size([3, 128, 8, 128])\n",
      "C_keys shape: torch.Size([3, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([3, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([3, 128, 8, 128])\n",
      "attention shape: torch.Size([3, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([3, 128, 8, 128])\n",
      "Partition Start 128, Partition End 256 , ponder_scores: torch.Size([3, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([3, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([3, 128, 8, 128])\n",
      "queries_part shape: torch.Size([3, 128, 8, 128])\n",
      "C_keys shape: torch.Size([3, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([3, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([3, 128, 8, 128])\n",
      "attention shape: torch.Size([3, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([3, 128, 8, 128])\n",
      "Partition Start 256, Partition End 384 , ponder_scores: torch.Size([3, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([3, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([3, 128, 8, 128])\n",
      "queries_part shape: torch.Size([3, 128, 8, 128])\n",
      "C_keys shape: torch.Size([3, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([3, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([3, 128, 8, 128])\n",
      "attention shape: torch.Size([3, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([3, 128, 8, 128])\n",
      "Partition Start 384, Partition End 512 , ponder_scores: torch.Size([3, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([3, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([3, 128, 8, 128])\n",
      "queries_part shape: torch.Size([3, 128, 8, 128])\n",
      "C_keys shape: torch.Size([3, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([3, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([3, 128, 8, 128])\n",
      "attention shape: torch.Size([3, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([3, 128, 8, 128])\n",
      "Partition Start 512, Partition End 640 , ponder_scores: torch.Size([3, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([3, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([3, 128, 8, 128])\n",
      "queries_part shape: torch.Size([3, 128, 8, 128])\n",
      "C_keys shape: torch.Size([3, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([3, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([3, 128, 8, 128])\n",
      "attention shape: torch.Size([3, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([3, 128, 8, 128])\n",
      "Partition Start 640, Partition End 768 , ponder_scores: torch.Size([3, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([3, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([3, 128, 8, 128])\n",
      "queries_part shape: torch.Size([3, 128, 8, 128])\n",
      "C_keys shape: torch.Size([3, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([3, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([3, 128, 8, 128])\n",
      "attention shape: torch.Size([3, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([3, 128, 8, 128])\n",
      "Partition Start 768, Partition End 896 , ponder_scores: torch.Size([3, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([3, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([3, 128, 8, 128])\n",
      "queries_part shape: torch.Size([3, 128, 8, 128])\n",
      "C_keys shape: torch.Size([3, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([3, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([3, 128, 8, 128])\n",
      "attention shape: torch.Size([3, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([3, 128, 8, 128])\n",
      "Partition Start 896, Partition End 1024 , ponder_scores: torch.Size([3, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([3, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([3, 128, 8, 128])\n",
      "queries_part shape: torch.Size([3, 128, 8, 128])\n",
      "C_keys shape: torch.Size([3, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([3, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([3, 128, 8, 128])\n",
      "attention shape: torch.Size([3, 128, 8, 128])\n",
      "values shape: torch.Size([3, 8, 1024, 64])\n",
      "values.reshape(-1, self.head_dim) shape: torch.Size([24576, 64])\n",
      "self.value_projection(values) shape: torch.Size([24576, 128])\n",
      "projected_values shape: torch.Size([3, 8, 1024, 128])\n",
      "2ND EINSUM\n",
      "out shape after einsum: torch.Size([3, 8, 1024, 128])\n",
      "out reshaped for projection: torch.Size([3072, 1024])\n",
      "out after final_projection: torch.Size([3072, 2749])\n",
      "Epoch 4, Loss: 7.923460483551025\n",
      "Batch 0 input_ids shape: torch.Size([3, 1024]), labels shape: torch.Size([3, 1024])\n",
      "input_ids: torch.Size([3, 1024])\n",
      "labels: torch.Size([3, 1024])\n",
      "BEGIN FORWARD\n",
      "x input shape: torch.Size([3, 1024, 512])\n",
      "x_reshaped shape: torch.Size([3, 1024, 8, 64])\n",
      "values : torch.Size([3, 1024, 8, 64])\n",
      "queries : torch.Size([3, 1024, 8, 128])\n",
      "keys : torch.Size([3, 1024, 8, 128])\n",
      "attention_scores after random projection: torch.Size([3, 8, 1024, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([3, 128, 8, 128])\n",
      "Partition Start 0, Partition End 128 , ponder_scores: torch.Size([3, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([3, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([3, 128, 8, 128])\n",
      "queries_part shape: torch.Size([3, 128, 8, 128])\n",
      "C_keys shape: torch.Size([3, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([3, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([3, 128, 8, 128])\n",
      "attention shape: torch.Size([3, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([3, 128, 8, 128])\n",
      "Partition Start 128, Partition End 256 , ponder_scores: torch.Size([3, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([3, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([3, 128, 8, 128])\n",
      "queries_part shape: torch.Size([3, 128, 8, 128])\n",
      "C_keys shape: torch.Size([3, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([3, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([3, 128, 8, 128])\n",
      "attention shape: torch.Size([3, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([3, 128, 8, 128])\n",
      "Partition Start 256, Partition End 384 , ponder_scores: torch.Size([3, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([3, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([3, 128, 8, 128])\n",
      "queries_part shape: torch.Size([3, 128, 8, 128])\n",
      "C_keys shape: torch.Size([3, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([3, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([3, 128, 8, 128])\n",
      "attention shape: torch.Size([3, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([3, 128, 8, 128])\n",
      "Partition Start 384, Partition End 512 , ponder_scores: torch.Size([3, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([3, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([3, 128, 8, 128])\n",
      "queries_part shape: torch.Size([3, 128, 8, 128])\n",
      "C_keys shape: torch.Size([3, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([3, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([3, 128, 8, 128])\n",
      "attention shape: torch.Size([3, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([3, 128, 8, 128])\n",
      "Partition Start 512, Partition End 640 , ponder_scores: torch.Size([3, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([3, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([3, 128, 8, 128])\n",
      "queries_part shape: torch.Size([3, 128, 8, 128])\n",
      "C_keys shape: torch.Size([3, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([3, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([3, 128, 8, 128])\n",
      "attention shape: torch.Size([3, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([3, 128, 8, 128])\n",
      "Partition Start 640, Partition End 768 , ponder_scores: torch.Size([3, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([3, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([3, 128, 8, 128])\n",
      "queries_part shape: torch.Size([3, 128, 8, 128])\n",
      "C_keys shape: torch.Size([3, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([3, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([3, 128, 8, 128])\n",
      "attention shape: torch.Size([3, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([3, 128, 8, 128])\n",
      "Partition Start 768, Partition End 896 , ponder_scores: torch.Size([3, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([3, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([3, 128, 8, 128])\n",
      "queries_part shape: torch.Size([3, 128, 8, 128])\n",
      "C_keys shape: torch.Size([3, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([3, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([3, 128, 8, 128])\n",
      "attention shape: torch.Size([3, 128, 8, 128])\n",
      "PARTITION START\n",
      "C_keys shape before return: torch.Size([3, 128, 8, 128])\n",
      "Partition Start 896, Partition End 1024 , ponder_scores: torch.Size([3, 8, 128, 1])\n",
      "BEFORE 1ST EINSUM:\n",
      "ponder_scores_permuted shape: torch.Size([3, 128, 8, 1])\n",
      "ponder_scores_broadcastable shape: torch.Size([3, 128, 8, 128])\n",
      "queries_part shape: torch.Size([3, 128, 8, 128])\n",
      "C_keys shape: torch.Size([3, 128, 8, 128])\n",
      "AFTER 1ST EINSUM:\n",
      "energy shape: torch.Size([3, 128, 8, 128])\n",
      "attention_weights shape: torch.Size([3, 128, 8, 128])\n",
      "attention shape: torch.Size([3, 128, 8, 128])\n",
      "values shape: torch.Size([3, 8, 1024, 64])\n",
      "values.reshape(-1, self.head_dim) shape: torch.Size([24576, 64])\n",
      "self.value_projection(values) shape: torch.Size([24576, 128])\n",
      "projected_values shape: torch.Size([3, 8, 1024, 128])\n",
      "2ND EINSUM\n",
      "out shape after einsum: torch.Size([3, 8, 1024, 128])\n",
      "out reshaped for projection: torch.Size([3072, 1024])\n",
      "out after final_projection: torch.Size([3072, 2749])\n",
      "Epoch 5, Loss: 7.9232940673828125\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from datasets import load_dataset\n",
    "# Test on larger text\n",
    "import re\n",
    "import collections\n",
    "from collections import Counter, defaultdict\n",
    "import json\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from datasets import load_dataset\n",
    "from transformers import BertTokenizer\n",
    "from torch.utils.data import DataLoader\n",
    "import fitz  # PyMuPDF\n",
    "from transformers import BertModel\n",
    "import math\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "from tqdm.notebook import tqdm\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "\n",
    "class SPLASH(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size, heads, sequence_length, projection_dim, partition_size):\n",
    "        super().__init__()\n",
    "        # Embedding layer added\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
    "        # Existing initialization code...\n",
    "        self.embed_size = embed_size\n",
    "        self.heads = heads\n",
    "        self.sequence_length = sequence_length\n",
    "        self.projection_dim = projection_dim\n",
    "        self.partition_size = partition_size\n",
    "        self.head_dim = embed_size // heads\n",
    "\n",
    "        self.values = nn.Linear(self.head_dim, self.head_dim, bias=False)\n",
    "        self.keys = nn.Linear(self.head_dim, self.projection_dim, bias=False)\n",
    "        self.queries = nn.Linear(self.head_dim, self.projection_dim, bias=False)\n",
    "        self.value_projection = nn.Linear(self.head_dim, self.projection_dim//2)  # To project values to match dimensions\n",
    "        self.ponder = nn.Linear(self.partition_size, 1, bias=True)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.final_projection = nn.Linear(self.heads * (self.projection_dim // 2), vocab_size)\n",
    "\n",
    "\n",
    "    def random_projection(self, matrix, k):\n",
    "        \"\"\"Random projection to reduce dimensionality of matrix to k dimensions.\"\"\"\n",
    "        random_matrix = torch.randn(matrix.size(-1), k, device=matrix.device)\n",
    "        return torch.matmul(matrix, random_matrix)\n",
    "\n",
    "    def cur_decomposition(self, matrix, projection_dim):\n",
    "        \"\"\"Applies CUR decomposition with C matrix dimension aligned to projection dimension.\"\"\"\n",
    "        batch_size, seq_length, heads, dim = matrix.shape\n",
    "        k = min(projection_dim // 2, dim)\n",
    "        C = torch.zeros(batch_size, seq_length, heads, k, device=matrix.device)\n",
    "        R = torch.zeros(batch_size, k, heads, dim, device=matrix.device)\n",
    "\n",
    "        for b in range(batch_size):\n",
    "            for h in range(heads):\n",
    "                col_indices = np.random.choice(dim, k, replace=False)\n",
    "                row_indices = np.random.choice(seq_length, k, replace=False)\n",
    "                C[b, :, h] = matrix[b, :, h, col_indices]\n",
    "                R[b, :, h] = matrix[b, row_indices, h]\n",
    "        return C, R\n",
    "\n",
    "    def forward(self, input_ids):\n",
    "        print(f\"BEGIN FORWARD\")\n",
    "        x = self.embedding(input_ids)\n",
    "        print(f\"x input shape: {x.shape}\")\n",
    "        N, seq_length, _ = x.shape\n",
    "        x_reshaped = x.view(N, seq_length, self.heads, self.head_dim)\n",
    "        print(f\"x_reshaped shape: {x_reshaped.shape}\")\n",
    "\n",
    "        values = self.values(x_reshaped)\n",
    "        queries = self.random_projection(self.queries(x_reshaped), self.projection_dim // 2)\n",
    "        keys = self.random_projection(self.keys(x_reshaped), self.projection_dim // 2 )\n",
    "        print(\"values :\", values.shape)\n",
    "        print(\"queries :\", queries.shape)\n",
    "        print(\"keys :\", keys.shape)\n",
    "\n",
    "        attention_scores = torch.zeros(N, self.heads, seq_length, self.projection_dim // 2, device=x.device)\n",
    "        print(f\"attention_scores after random projection: {attention_scores.shape}\")\n",
    "\n",
    "        for i in range(0, seq_length, self.partition_size):\n",
    "            print(f\"PARTITION START\")\n",
    "            partition_start = i\n",
    "            partition_end = min(i + self.partition_size, seq_length)\n",
    "            keys_part = keys[:, partition_start:partition_end, :, :]\n",
    "            queries_part = queries[:, partition_start:partition_end, :, :]\n",
    "\n",
    "            C_keys, R_queries = self.cur_decomposition(keys_part, self.projection_dim)\n",
    "            print(\"C_keys shape before return:\", C_keys.shape)\n",
    "\n",
    "            ponder_scores = torch.zeros(N, self.heads, partition_end - partition_start, 1, device=x.device)\n",
    "            print(f\"Partition Start {i}, Partition End {partition_end} , ponder_scores: {ponder_scores.shape}\")\n",
    "\n",
    "            for h in range(self.heads):\n",
    "                #print(f\"HEADS START\")\n",
    "                head_queries = queries_part[:, :, h, :]\n",
    "                #print(f\"head_queries: {head_queries.shape}\")\n",
    "                head_ponder_scores = self.sigmoid(self.ponder(head_queries))\n",
    "                #print(f\"head_ponder_scores: {head_ponder_scores.shape}\")\n",
    "                ponder_scores[:, h, :, 0] = head_ponder_scores.squeeze(-1)\n",
    "\n",
    "            # Correctly expand ponder_scores without adding an unnecessary dimension\n",
    "            print(\"BEFORE 1ST EINSUM:\")\n",
    "            ponder_scores_permuted = ponder_scores.permute(0, 2, 1, 3)  # Move to [2, 128, 8, 1]\n",
    "            print(\"ponder_scores_permuted shape:\", ponder_scores_permuted.shape) \n",
    "            ponder_scores_broadcastable = ponder_scores_permuted.expand(-1, -1, -1, 128)  # Expand to [2, 128, 8, 128]            \n",
    "            print(\"ponder_scores_broadcastable shape:\", ponder_scores_broadcastable.shape) \n",
    "            print(\"queries_part shape:\", queries_part.shape) \n",
    "            print(\"C_keys shape:\", C_keys.shape)\n",
    "            energy = torch.einsum('bnhd,bnhk->bnhd', queries_part, C_keys)\n",
    "            attention_weights = F.softmax(energy, dim=-1)\n",
    "            print(\"AFTER 1ST EINSUM:\")\n",
    "            print(\"energy shape:\", energy.shape) \n",
    "            print(\"attention_weights shape:\", attention_weights.shape)\n",
    "            attention = attention_weights * ponder_scores_broadcastable\n",
    "            print(\"attention shape:\", attention.shape)\n",
    "            attention_corrected = attention.permute(0, 2, 1, 3)\n",
    "            attention_scores[:, :, partition_start:partition_end, :] = attention_corrected\n",
    "\n",
    "        values = values.permute(0, 2, 1, 3)  # Swap heads and seq_length to bring heads next to head_dim\n",
    "        print(\"values shape:\", values.shape)\n",
    "        values = values.reshape(-1, self.head_dim)  # Flatten to [N*heads*seq_length, head_dim] for linear layer\n",
    "        print(\"values.reshape(-1, self.head_dim) shape:\", values.shape)\n",
    "        projected_values = self.value_projection(values)  # Now [N*heads*seq_length, projection_dim / 2]\n",
    "        print(\"self.value_projection(values) shape:\", projected_values.shape)\n",
    "        projected_values = projected_values.view(N, self.heads, seq_length, self.projection_dim // 2)\n",
    "        print(\"projected_values shape:\", projected_values.shape)\n",
    "\n",
    "        print(f\"2ND EINSUM\")\n",
    "        # Combine attention_scores and projected_values then pass through the final linear layer\n",
    "        '''out = torch.einsum('bnhp,bnhp->bnh', attention_scores, projected_values)\n",
    "        print(\"out shape:\", out.shape)\n",
    "        out = self.final_projection(out.view(-1, self.embed_size))  # Reshape and project\n",
    "        print(f\"out from self.final_projection(out.view(-1, self.embed_size)) : {out.shape}\")\n",
    "        print(f\"Final output: { out.view(-1, vocab_size).shape }\")\n",
    "        return out.view(-1, vocab_size)  # Reshape to [batch_size, sequence_length, vocab_size]'''\n",
    "        # Combine attention_scores and projected_values then pass through the final linear layer\n",
    "        out = torch.einsum('bnhp,bnhp->bnhp', attention_scores, projected_values)\n",
    "        print(\"out shape after einsum:\", out.shape)\n",
    "\n",
    "        # Correct reshaping: Flatten batch and sequence length dimensions, keep the last two dimensions for projection\n",
    "        out = out.reshape(-1, self.heads * (self.projection_dim // 2))\n",
    "        print(\"out reshaped for projection:\", out.shape)\n",
    "\n",
    "        # Ensure the final_projection layer matches the flattened shape expected after reshaping\n",
    "        # Assuming final_projection is defined as nn.Linear(self.heads * (self.projection_dim // 2), vocab_size)\n",
    "        out = self.final_projection(out)\n",
    "        print(f\"out after final_projection:\", out.shape)\n",
    "\n",
    "        # At this point, out should have a shape of [batch_size * sequence_length, vocab_size], ready for loss calculation\n",
    "        return out\n",
    "\n",
    "##################################################\n",
    "# Tokenizer\n",
    "\n",
    "class TrieNode:\n",
    "    def __init__(self):\n",
    "        self.children = {}\n",
    "        self.token_id = None\n",
    "        self.frequency = 0\n",
    "        self.failure_link = None\n",
    "        self.is_end = False  # Add is_end attribute to mark the end of a word\n",
    "        self.token = None  # Add token attribute to store the token associated with the node\n",
    "\n",
    "\n",
    "class Trie:\n",
    "    def __init__(self, unk_token_id=0):\n",
    "        self.root = TrieNode()\n",
    "        self.unk_token_id = unk_token_id\n",
    "\n",
    "    def insert(self, token, token_id, frequency):\n",
    "        node = self.root\n",
    "        for char in token:\n",
    "            if char not in node.children:\n",
    "                node.children[char] = TrieNode()\n",
    "            node = node.children[char]\n",
    "        node.token_id = token_id\n",
    "        node.frequency = frequency\n",
    "\n",
    "    def find_subwords(self, token):\n",
    "        \"\"\"Finds the most probable subwords based on frequency.\"\"\"\n",
    "        node = self.root\n",
    "        best_subwords = []\n",
    "\n",
    "        def dfs(current_node, subword='', collected_subwords=[]):\n",
    "            if current_node.token_id is not None:\n",
    "                # Update to correctly calculate total_frequency based on the structure of collected_subwords\n",
    "                total_frequency = sum(n.frequency for _, _, n in collected_subwords) + current_node.frequency\n",
    "                probability = current_node.frequency / total_frequency if total_frequency else 0\n",
    "                collected_subwords.append((subword, probability, current_node))\n",
    "\n",
    "            for char, next_node in current_node.children.items():\n",
    "                dfs(next_node, subword + char, list(collected_subwords))  # Create a copy of the list to avoid shared state\n",
    "\n",
    "        dfs(node)\n",
    "        best_subwords = sorted(best_subwords, key=lambda x: x[1], reverse=True)\n",
    "        return [subword for subword, _, _ in best_subwords][:5] or [self.unk_token_id]\n",
    "\n",
    "\n",
    "    def compute_failure_links(self):\n",
    "        root = self.root\n",
    "        root.failure_link = root  # Root's failure link points to itself\n",
    "        queue = [root]\n",
    "\n",
    "        while queue:\n",
    "            current_node = queue.pop(0)\n",
    "\n",
    "            for char, child_node in current_node.children.items():\n",
    "                queue.append(child_node)\n",
    "\n",
    "                # Follow failure link to find the longest suffix for the child_node\n",
    "                failure_candidate = current_node.failure_link\n",
    "                while failure_candidate != root and char not in failure_candidate.children:\n",
    "                    failure_candidate = failure_candidate.failure_link\n",
    "                child_node.failure_link = failure_candidate.children.get(char, root)\n",
    "\n",
    "\n",
    "class SimpleSentencePiece:\n",
    "    def __init__(self, model_type=\"bpe\", vocab_size=30522):\n",
    "        self.vocab = {}\n",
    "        self.id_to_subword = {}\n",
    "        self.unk_token = \"[UNK]\"\n",
    "        self.unk_token_id = 0\n",
    "        self.vocab_size = vocab_size\n",
    "        self.model = None if model_type == \"bpe\" else None\n",
    "        self.model_type = model_type\n",
    "\n",
    "    def train(self, text):\n",
    "        if self.model_type == \"bpe\":\n",
    "            self.model = BPE(num_merges=self.vocab_size, unk_token_id=self.unk_token_id)\n",
    "            self.model.train(text)\n",
    "            self.vocab = self.model.vocab\n",
    "            self.id_to_subword = {i: word for word, i in self.vocab.items()}\n",
    "        else:\n",
    "            raise NotImplementedError(f\"Model type {self.model_type} not supported yet.\")\n",
    "\n",
    "    def encode(self, text):\n",
    "        text = self.preprocess_text(text)  # Preprocess text before encoding\n",
    "        if not self.model:\n",
    "            raise ValueError(\"Model has not been trained yet.\")\n",
    "        encoded = self.model.encode(text)\n",
    "        #print(f\"Encoded: {encoded[:10]}\")  # Print first 10 encoded tokens\n",
    "        return encoded\n",
    "\n",
    "    def decode(self, ids):\n",
    "        if not self.id_to_subword:\n",
    "            raise ValueError(\"Vocabulary is empty. Ensure the model is trained first.\")\n",
    "        text = \" \".join([self.id_to_subword.get(id_, self.unk_token) for id_ in ids])\n",
    "        text = text.replace(\" </w>\", \"\").replace(\"</w>\", \" \").strip()\n",
    "        return text\n",
    "\n",
    "    def preprocess_text(self, text):\n",
    "        # Convert text to lowercase to ensure case insensitivity\n",
    "        text = text.lower()\n",
    "        # Optionally, handle punctuation by adding spaces around it for better tokenization\n",
    "        text = re.sub(r'([.,!?()])', r' \\1 ', text)\n",
    "        # Replace multiple spaces with a single space\n",
    "        text = re.sub(r'\\s+', ' ', text)\n",
    "        # Trim leading and trailing spaces\n",
    "        text = text.strip()\n",
    "        return text\n",
    "    \n",
    "    def save_model(self, filepath):\n",
    "        model_data = {\n",
    "            'vocab': self.vocab,\n",
    "            'id_to_subword': self.id_to_subword,\n",
    "            'model_type': self.model_type,\n",
    "            'vocab_size': self.vocab_size,\n",
    "            # Potentially include other relevant attributes\n",
    "        }\n",
    "        # Save the high-level tokenizer settings\n",
    "        with open(filepath, 'w') as f:\n",
    "            json.dump(model_data, f)\n",
    "        \n",
    "        # Now save the BPE model specifically\n",
    "        if self.model_type == \"bpe\" and self.model:\n",
    "            self.model.save_model(filepath + \"_bpe\")\n",
    "\n",
    "    def load_model(self, filepath):\n",
    "        with open(filepath, 'r') as f:\n",
    "            model_data = json.load(f)\n",
    "        \n",
    "        self.vocab = model_data['vocab']\n",
    "        self.id_to_subword = model_data['id_to_subword']\n",
    "        self.model_type = model_data['model_type']\n",
    "        self.vocab_size = model_data['vocab_size']\n",
    "        \n",
    "        # Assuming model_type is still \"bpe\", we now load the BPE model\n",
    "        if self.model_type == \"bpe\":\n",
    "            self.model = BPE(self.vocab_size, self.unk_token_id)\n",
    "            self.model.load_model(filepath + \"_bpe\")\n",
    "\n",
    "class BPE:\n",
    "    def __init__(self, num_merges=100, unk_token_id=0):  # Accept unk_token_id parameter\n",
    "        self.vocab = {}\n",
    "        self.merges = []\n",
    "        self.num_merges = num_merges\n",
    "        self.unk_token_id = unk_token_id  # Store the unknown token ID\n",
    "\n",
    "    def train(self, text):\n",
    "        words = re.findall(r'\\w+|[^\\w\\s]', text, re.UNICODE)\n",
    "        vocab = collections.Counter(words)\n",
    "        vocab = {word + '</w>': count for word, count in vocab.items()}\n",
    "        \n",
    "        for _ in range(self.num_merges):  # Use the num_merges from the instance variable\n",
    "            pairs = self.get_stats(vocab)\n",
    "            if not pairs:\n",
    "                break\n",
    "            best = max(pairs, key=pairs.get)\n",
    "            vocab = self.merge_vocab(best, vocab)\n",
    "            self.merges.append(best)\n",
    "\n",
    "        self.vocab = {word: i for i, word in enumerate(vocab.keys())}\n",
    "\n",
    "    @staticmethod\n",
    "    def get_stats(vocab):\n",
    "        pairs = collections.defaultdict(int)\n",
    "        for word, freq in vocab.items():\n",
    "            symbols = word.split()\n",
    "            for i in range(len(symbols)-1):\n",
    "                pairs[symbols[i], symbols[i+1]] += freq\n",
    "        return pairs\n",
    "\n",
    "    @staticmethod\n",
    "    def merge_vocab(pair, vocab):\n",
    "        v_out = {}\n",
    "        bigram = re.escape(' '.join(pair))\n",
    "        p = re.compile(r'(?<!\\S)' + bigram + r'(?!\\S)')\n",
    "        for word in vocab:\n",
    "            w_out = p.sub(''.join(pair), word)\n",
    "            v_out[w_out] = vocab[word]\n",
    "        return v_out\n",
    "\n",
    "    def encode(self, text):\n",
    "        \"\"\"Encode text into subwords using learned BPE merges.\"\"\"\n",
    "        encoded_tokens = []\n",
    "        for word in re.findall(r'\\w+|[^\\w\\s]', text, re.UNICODE):\n",
    "            word += '</w>'\n",
    "            subwords = [word]  # Start with the entire word as one subword\n",
    "            for merge in self.merges:\n",
    "                new_subwords = []\n",
    "                for subword in subwords:\n",
    "                    # If the merge is in subword, split it; otherwise, keep it as is\n",
    "                    if ' '.join(merge) in subword:\n",
    "                        new_subwords.extend(subword.replace(' '.join(merge), ''.join(merge)).split(' '))\n",
    "                    else:\n",
    "                        new_subwords.append(subword)\n",
    "                subwords = new_subwords\n",
    "            encoded_tokens.extend(subwords)\n",
    "        return [self.vocab.get(token, self.unk_token_id) for token in encoded_tokens]\n",
    "    \n",
    "        # New method to save trained model\n",
    "    def save_model(self, filepath):\n",
    "        bpe_data = {\n",
    "            'merges': self.merges,\n",
    "            'vocab': self.vocab,\n",
    "            'num_merges': self.num_merges,\n",
    "            # Include other attributes as needed\n",
    "        }\n",
    "        with open(filepath, 'w') as f:\n",
    "            json.dump(bpe_data, f)\n",
    "\n",
    "    def load_model(self, filepath):\n",
    "        with open(filepath, 'r') as f:\n",
    "            bpe_data = json.load(f)\n",
    "        \n",
    "        self.merges = bpe_data['merges']\n",
    "        self.vocab = bpe_data['vocab']\n",
    "        self.num_merges = bpe_data['num_merges']\n",
    "\n",
    "\n",
    "class WordPiece:\n",
    "    def __init__(self, vocab, unk_token_id=0, unk_token=\"[UNK]\"):\n",
    "        self.vocab = vocab\n",
    "        self.unk_token_id = unk_token_id\n",
    "        self.unk_token = unk_token  # Define the unknown token\n",
    "        self.root = self.build_trie(vocab)\n",
    "        self.id_to_token = {id_: token for token, id_ in vocab.items()}  # Inverse mapping\n",
    "        self.compute_failure_links(self.root)\n",
    "        print(\"Trie built successfully.\")\n",
    "\n",
    "    def convert_ids_to_tokens(self, ids):\n",
    "        \"\"\"\n",
    "        Convert a list of token ids back to their string token representations.\n",
    "        \"\"\"\n",
    "        return [self.id_to_token.get(id_, self.unk_token) for id_ in ids]\n",
    "\n",
    "    # Add debug prints to build_trie to confirm structure\n",
    "    def build_trie(self, vocab):\n",
    "        root = TrieNode()\n",
    "        for token in vocab:\n",
    "            node = root\n",
    "            for char in token:\n",
    "                if char not in node.children:\n",
    "                    node.children[char] = TrieNode()\n",
    "                node = node.children[char]\n",
    "            node.is_end = True\n",
    "            node.token = token\n",
    "        #print(\"Trie Construction Completed Successfully\")\n",
    "        return root\n",
    "\n",
    "\n",
    "    def compute_failure_links(self, root):\n",
    "        queue = [root]\n",
    "        while queue:\n",
    "            current_node = queue.pop(0)\n",
    "            for char, child_node in current_node.children.items():\n",
    "                failure_node = current_node.failure_link\n",
    "                while failure_node and char not in failure_node.children:\n",
    "                    failure_node = failure_node.failure_link\n",
    "                child_node.failure_link = failure_node.children[char] if failure_node else root\n",
    "                queue.append(child_node)\n",
    "\n",
    "    # Improved debug prints in tokenize method\n",
    "                \n",
    "    def tokenize(self, text):\n",
    "        # Preprocess input text\n",
    "        text = self.preprocess_text(text)\n",
    "        node = self.root\n",
    "        token_ids = []  # Will store token IDs instead of tokens\n",
    "        i = 0\n",
    "\n",
    "        while i < len(text):\n",
    "            char = text[i]\n",
    "            if char == ' ':\n",
    "                node = self.root\n",
    "                i += 1\n",
    "                continue\n",
    "\n",
    "            if char not in node.children:\n",
    "                if node != self.root and node.token is not None:\n",
    "                    # Convert found token to its ID\n",
    "                    token_id = self.vocab.get(node.token, self.unk_token_id)\n",
    "                    token_ids.append(token_id)\n",
    "                    node = self.root  # Reset to root\n",
    "                    continue\n",
    "                else:\n",
    "                    # Append unknown token ID\n",
    "                    token_ids.append(self.unk_token_id)\n",
    "                    i += 1\n",
    "                    continue\n",
    "\n",
    "            node = node.children[char]\n",
    "            if node.is_end:\n",
    "                if i + 1 == len(text) or text[i + 1] == ' ':\n",
    "                    # Convert found token to its ID\n",
    "                    token_id = self.vocab.get(node.token, self.unk_token_id)\n",
    "                    token_ids.append(token_id)\n",
    "                    node = self.root\n",
    "\n",
    "            i += 1\n",
    "\n",
    "        #print(f\"Token IDs: {token_ids[:10]}\")\n",
    "        return token_ids\n",
    "\n",
    "    def preprocess_text(self, text):\n",
    "        # Convert text to lowercase to ensure case insensitivity\n",
    "        text = text.lower()\n",
    "\n",
    "        # Optionally, handle punctuation by adding spaces around it for better tokenization\n",
    "        # This depends on how your vocabulary handles punctuation\n",
    "        text = re.sub(r'([.,!?()])', r' \\1 ', text)\n",
    "\n",
    "        # Replace multiple spaces with a single space\n",
    "        text = re.sub(r'\\s+', ' ', text)\n",
    "\n",
    "        # Trim leading and trailing spaces\n",
    "        text = text.strip()\n",
    "\n",
    "        return text\n",
    "\n",
    "\n",
    "def load_corpus(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        texts = [line.strip() for line in file.readlines()]\n",
    "    return texts\n",
    "\n",
    "texts = load_corpus(\"D:\\\\EXPERT_WEIGHTS\\\\sample.txt\")\n",
    "#texts = load_corpus(\"/content/drive/MyDrive/EXPERT_STUFF/sample.txt\")\n",
    "# texts = load_corpus(\"C:/Users/robbi/Expert/sample.txt\")\n",
    "num_merges = 100\n",
    "def adapt_vocab_for_wordpiece(ssp_vocab):\n",
    "    adapted_vocab = {}\n",
    "    for token, id_or_freq in ssp_vocab.items():\n",
    "        if not token.startswith(\" \") and not token.endswith(\"</w>\"):\n",
    "            adapted_token = \"##\" + token.replace(\"</w>\", \"\")\n",
    "        else:\n",
    "            adapted_token = token.replace(\"</w>\", \"\")\n",
    "        adapted_vocab[adapted_token] = id_or_freq\n",
    "    return adapted_vocab\n",
    "\n",
    "# Initialize and train the SimpleSentencePiece model with BPE\n",
    "ssp = SimpleSentencePiece(model_type=\"bpe\", vocab_size=30522)\n",
    "# Assume `texts` is a list of text to train the tokenizer\n",
    "ssp.train('\\n'.join(texts))\n",
    "wordpiece_vocab = adapt_vocab_for_wordpiece(ssp.vocab)\n",
    "# Debugging step to ensure vocabulary completeness\n",
    "def debug_vocab(adapted_vocab):\n",
    "    print(\"Sample Vocabulary Check:\")\n",
    "    # Iterate over the first 10 key-value pairs in the adapted vocabulary\n",
    "    for i, (token, id_or_freq) in enumerate(adapted_vocab.items()):\n",
    "        print(f\"{token}: {id_or_freq}\")\n",
    "        if i >= 9:  # Stop after printing 10 entries\n",
    "            break\n",
    "    # Specifically check for subtokens if your tokenizer expects them\n",
    "    subtokens = [token for token in adapted_vocab.keys() if token.startswith(\"##\")]\n",
    "    print(f\"Found {len(subtokens)} subtokens in vocabulary.\")\n",
    "\n",
    "# Ensure wordpiece_vocab is a list of vocabulary tokens\n",
    "# debug_vocab(wordpiece_vocab)  # Call this after initializing wordpiece_vocab\n",
    "\n",
    "# Initialize WordPiece with the adapted vocabulary\n",
    "wordpiece_tokenizer = WordPiece(wordpiece_vocab, unk_token_id=0, unk_token=\"[UNK]\")\n",
    "\n",
    "\n",
    "class WikiTextDatasetForLM(Dataset):\n",
    "    def __init__(self, texts, tokenizer, sequence_length):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.sequence_length = sequence_length\n",
    "        self.inputs, self.labels = self.process_texts(texts)\n",
    "        \n",
    "    def process_texts(self, texts):\n",
    "        inputs, labels = [], []\n",
    "        step_size = 256  # Example step size for overlapping sequences\n",
    "        for text in texts:\n",
    "            token_ids = self.tokenizer.tokenize(text)\n",
    "            for i in range(0, len(token_ids) - self.sequence_length, step_size):  # Adjust step_size for overlap\n",
    "                inputs.append(token_ids[i:i+self.sequence_length])\n",
    "                labels.append(token_ids[i+1:i+self.sequence_length+1])\n",
    "        return torch.tensor(inputs, dtype=torch.long), torch.tensor(labels, dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.inputs[idx], self.labels[idx]\n",
    "\n",
    "\n",
    "# Assuming vocab_size is determined by your tokenizer's vocabulary size\n",
    "vocab_size = len(wordpiece_tokenizer.vocab)  # Adjust this to match your tokenizer's vocab size method\n",
    "print(vocab_size)\n",
    "# Define other parameters for SPLASH model instantiation\n",
    "embed_size = 512  # Embedding size\n",
    "heads = 8  # Number of attention heads\n",
    "sequence_length = 1024  # Input sequence length\n",
    "projection_dim = 256  # Dimension for projections inside SPLASH\n",
    "partition_size = 128  # Size of partitions for SPLASH processing\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Instantiate SPLASH Model\n",
    "splash_model = SPLASH(vocab_size=vocab_size, embed_size=embed_size, heads=heads, \n",
    "                      sequence_length=sequence_length, projection_dim=projection_dim, \n",
    "                      partition_size=partition_size).to(device)\n",
    "\n",
    "# Load Wikipedia dataset and preprocess\n",
    "dataset = load_dataset(\"wikitext\", \"wikitext-2-v1\", split=\"train\")\n",
    "batch_size = 32  # Adjust based on your hardware capabilities\n",
    "num_epochs  = 5\n",
    "loss_function = nn.CrossEntropyLoss()  # Example, adjust as needed\n",
    "optimizer = torch.optim.Adam(splash_model.parameters(), lr=1e-4)\n",
    "# Extract texts from the dataset\n",
    "texts = dataset['text']\n",
    "\n",
    "# Initialize the dataset for language modeling\n",
    "wiki_dataset_for_lm = WikiTextDatasetForLM(texts, wordpiece_tokenizer, sequence_length=1024)\n",
    "print(f\"len(wiki_dataset_for_lm): {len(wiki_dataset_for_lm)}\")\n",
    "\n",
    "# DataLoader\n",
    "data_loader = DataLoader(wiki_dataset_for_lm, batch_size=32, shuffle=True)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (input_ids, labels) in enumerate(data_loader):\n",
    "        print(f\"Batch {i} input_ids shape: {input_ids.shape}, labels shape: {labels.shape}\")\n",
    "        if i > 5:  # Just to limit output for debugging\n",
    "            break\n",
    "\n",
    "    for input_ids, labels in data_loader:\n",
    "        input_ids, labels = input_ids.to(device), labels.to(device)\n",
    "        print(f\"input_ids: {input_ids.shape}\")\n",
    "        print(f\"labels: {labels.shape}\")\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = splash_model(input_ids)\n",
    "\n",
    "        # Flatten the output and label tensors for use with CrossEntropyLoss\n",
    "        outputs_flat = outputs.view(-1, outputs.size(-1))\n",
    "        labels_flat = labels.view(-1)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = loss_function(outputs_flat, labels_flat)\n",
    "        \n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}, Loss: {loss.item()}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 1 length: 0 words\n",
      "Sample 2 length: 5 words\n",
      "Sample 3 length: 0 words\n",
      "Sample 4 length: 127 words\n",
      "Sample 5 length: 91 words\n",
      "Text length (tokens): 105648\n",
      "Generated 411 sequences from text\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import torch\n",
    "\n",
    "# Placeholder for a simple token to ID mapping\n",
    "token_to_id = {}\n",
    "next_id = 1  # Start with 1 since 0 might be reserved for padding\n",
    "\n",
    "def simulate_tokenize(text):\n",
    "    global next_id\n",
    "    # Split text into \"tokens\" based on spaces\n",
    "    tokens = text.split()\n",
    "    # Convert tokens to IDs\n",
    "    token_ids = []\n",
    "    for token in tokens:\n",
    "        if token not in token_to_id:\n",
    "            token_to_id[token] = next_id\n",
    "            next_id += 1\n",
    "        token_ids.append(token_to_id[token])\n",
    "    return token_ids\n",
    "\n",
    "def process_texts(texts, sequence_length=512, step_size=256):\n",
    "    inputs, labels = [], []\n",
    "    for text in texts:\n",
    "        token_ids = simulate_tokenize(text)\n",
    "        print(f\"Text length (tokens): {len(token_ids)}\")\n",
    "        num_sequences = 0\n",
    "        for i in range(0, len(token_ids) - sequence_length, step_size):\n",
    "            inputs.append(token_ids[i:i+sequence_length])\n",
    "            labels.append(token_ids[i+1:i+sequence_length+1])\n",
    "            num_sequences += 1\n",
    "        print(f\"Generated {num_sequences} sequences from text\")\n",
    "    # Convert lists of integers to tensors\n",
    "    return torch.tensor(inputs, dtype=torch.long), torch.tensor(labels, dtype=torch.long)\n",
    "\n",
    "# Load a subset of the dataset for demonstration\n",
    "dataset = load_dataset(\"wikitext\", \"wikitext-2-v1\", split=\"train[:5%]\")\n",
    "\n",
    "# Print lengths of a few sample texts\n",
    "texts = dataset['text'][:5]\n",
    "for i, text in enumerate(texts):\n",
    "    print(f\"Sample {i+1} length: {len(text.split())} words\")\n",
    "\n",
    "# Merge texts into a single continuous text\n",
    "continuous_text = ' '.join(dataset['text'])\n",
    "texts = [continuous_text]  # Now you have a single large text\n",
    "\n",
    "# Process the merged text\n",
    "inputs, labels = process_texts(texts)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_gpu_env_llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
