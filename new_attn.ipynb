{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# v4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x shape as input to forward: torch.Size([2, 1024, 512])\n",
      "embed size as input to forward: 512\n",
      "x_reshaped : torch.Size([2, 1024, 8, 64])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "shape '[2, 128, 1]' is invalid for input of size 512",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[73], line 104\u001b[0m\n\u001b[0;32m    102\u001b[0m model \u001b[38;5;241m=\u001b[39m PartitionedLinformerAttentionACT(embed_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m512\u001b[39m, heads\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m, sequence_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1024\u001b[39m, projection_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m256\u001b[39m, partition_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m128\u001b[39m)\n\u001b[0;32m    103\u001b[0m input_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrand(\u001b[38;5;241m2\u001b[39m, model\u001b[38;5;241m.\u001b[39msequence_length, model\u001b[38;5;241m.\u001b[39membed_size)\n\u001b[1;32m--> 104\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_tensor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    105\u001b[0m \u001b[38;5;28mprint\u001b[39m(output\u001b[38;5;241m.\u001b[39mshape)  \u001b[38;5;66;03m# Expected output shape: [2, sequence_length, embed_size]\u001b[39;00m\n\u001b[0;32m    108\u001b[0m \u001b[38;5;66;03m# Create a DataLoader with pinned memory\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\robbi\\anaconda3\\envs\\my_gpu_env_llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\robbi\\anaconda3\\envs\\my_gpu_env_llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[73], line 81\u001b[0m, in \u001b[0;36mPartitionedLinformerAttentionACT.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     78\u001b[0m head_queries \u001b[38;5;241m=\u001b[39m queries_partition[:, :, h, :]\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhead_dim)\n\u001b[0;32m     80\u001b[0m \u001b[38;5;66;03m# Apply the ponder network\u001b[39;00m\n\u001b[1;32m---> 81\u001b[0m head_ponder_scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msigmoid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mponder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhead_queries\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[43mN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartition_end\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mpartition_start\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     83\u001b[0m \u001b[38;5;66;03m# Reshape head_ponder_scores back to match the original batch and partition sizes\u001b[39;00m\n\u001b[0;32m     84\u001b[0m \u001b[38;5;66;03m# and expand the last dimension to match the expected shape for broadcasting\u001b[39;00m\n\u001b[0;32m     85\u001b[0m head_ponder_scores_reshaped \u001b[38;5;241m=\u001b[39m head_ponder_scores\u001b[38;5;241m.\u001b[39mview(N, partition_end \u001b[38;5;241m-\u001b[39m partition_start, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mexpand(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhead_dim)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: shape '[2, 128, 1]' is invalid for input of size 512"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from torch.optim import Adam\n",
    "\n",
    "\n",
    "\n",
    "def random_projection(matrix, k):\n",
    "    \"\"\"Random projection to reduce dimensionality of matrix to k dimensions.\"\"\"\n",
    "    random_matrix = torch.randn(matrix.size(-1), k, device=matrix.device)\n",
    "    return torch.matmul(matrix, random_matrix)\n",
    "\n",
    "def cur_decomposition(matrix, k):\n",
    "    \"\"\"Applies CUR decomposition on each head for each batch.\"\"\"\n",
    "    batch_size, seq_length, heads, dim = matrix.shape\n",
    "    # Ensuring k does not exceed dimensions\n",
    "    k = min(k, dim)\n",
    "    C = torch.zeros(batch_size, seq_length, heads, k, device=matrix.device)\n",
    "    R = torch.zeros(batch_size, k, heads, dim, device=matrix.device)\n",
    "    \n",
    "    for b in range(batch_size):\n",
    "        for h in range(heads):\n",
    "            col_indices = np.random.choice(dim, k, replace=False)\n",
    "            row_indices = np.random.choice(seq_length, k, replace=False)\n",
    "            C[b, :, h] = matrix[b, :, h, col_indices]\n",
    "            R[b, :, h] = matrix[b, row_indices, h]\n",
    "    return C, R\n",
    "\n",
    "class PartitionedLinformerAttentionACT(nn.Module):\n",
    "    def __init__(self, embed_size, heads, sequence_length, projection_dim, partition_size):\n",
    "        super().__init__()\n",
    "        self.embed_size = embed_size\n",
    "        self.heads = heads\n",
    "        self.sequence_length = sequence_length\n",
    "        self.projection_dim = projection_dim\n",
    "        self.partition_size = partition_size\n",
    "        self.head_dim = embed_size // heads\n",
    "\n",
    "        self.values = nn.Linear(self.head_dim, self.head_dim, bias=False)\n",
    "        self.keys = nn.Linear(self.head_dim, self.projection_dim, bias=False)\n",
    "        self.queries = nn.Linear(self.head_dim, self.projection_dim, bias=False)\n",
    "        self.fc_out = nn.Linear(heads * self.head_dim, embed_size)\n",
    "        self.ponder = nn.Linear(self.head_dim, 1, bias=True)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        N, seq_length, _ = x.shape\n",
    "        print(f\"x shape as input to forward: {x.shape}\")\n",
    "        print(f\"embed size as input to forward: {self.embed_size}\")\n",
    "\n",
    "        x_reshaped = x.view(N, seq_length, self.heads, self.head_dim)\n",
    "        print(f\"x_reshaped : {x_reshaped.shape}\")\n",
    "\n",
    "        values = self.values(x_reshaped).view(N, seq_length, self.heads, self.head_dim)\n",
    "        keys = self.keys(x_reshaped).view(N, seq_length, self.heads, self.projection_dim)\n",
    "        queries = self.queries(x_reshaped).view(N, seq_length, self.heads, self.projection_dim)\n",
    "\n",
    "        keys = random_projection(keys, self.projection_dim // 2)\n",
    "        queries = random_projection(queries, self.projection_dim // 2)\n",
    "\n",
    "        attention_scores = torch.zeros(N, self.heads, seq_length, self.projection_dim // 2, device=x.device)\n",
    "\n",
    "        for i in range(0, seq_length, self.partition_size):\n",
    "            partition_start = i\n",
    "            partition_end = min(i + self.partition_size, seq_length)\n",
    "            keys_partition = keys[:, partition_start:partition_end, :, :]\n",
    "            queries_partition = queries[:, partition_start:partition_end, :, :]\n",
    "\n",
    "            C_keys, R_queries = cur_decomposition(keys_partition, k=keys_partition.size(-1) // 2)\n",
    "\n",
    "            ponder_scores = torch.zeros(N, self.heads, partition_end - partition_start, 1, device=x.device)\n",
    "            for h in range(self.heads):\n",
    "                # Flatten the input tensor for each head across batch and sequence dimensions\n",
    "                # while keeping the head dimension intact for linear layer processing\n",
    "                head_queries = queries_partition[:, :, h, :].reshape(-1, self.head_dim)\n",
    "\n",
    "                # Apply the ponder network\n",
    "                head_ponder_scores = self.sigmoid(self.ponder(head_queries)).view(N, partition_end - partition_start, 1)\n",
    "\n",
    "                # Reshape head_ponder_scores back to match the original batch and partition sizes\n",
    "                # and expand the last dimension to match the expected shape for broadcasting\n",
    "                head_ponder_scores_reshaped = head_ponder_scores.view(N, partition_end - partition_start, -1).expand(-1, -1, self.head_dim)\n",
    "\n",
    "                # Assign the reshaped ponder scores back to the corresponding head in the ponder_scores tensor\n",
    "                ponder_scores[:, :, h, :] = head_ponder_scores_reshaped.squeeze(-1)\n",
    "\n",
    "            energy = torch.einsum('bnhdp,bnhpd->bnhdp', queries_partition, C_keys.transpose(-2, -1))\n",
    "            attention = F.softmax(energy, dim=-1) * ponder_scores\n",
    "            attention_scores[:, :, partition_start:partition_end, :] = attention\n",
    "\n",
    "        out = torch.einsum('bnhdp,bnhpd->bnshp', attention_scores, values).reshape(N, seq_length, -1)\n",
    "        return self.fc_out(out)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Example usage\n",
    "\n",
    "model = PartitionedLinformerAttentionACT(embed_size=512, heads=8, sequence_length=1024, projection_dim=256, partition_size=128)\n",
    "input_tensor = torch.rand(2, model.sequence_length, model.embed_size)\n",
    "output = model(input_tensor)\n",
    "print(output.shape)  # Expected output shape: [2, sequence_length, embed_size]\n",
    "\n",
    "\n",
    "# Create a DataLoader with pinned memory\n",
    "class MyDataset(Dataset):\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        # Initialize your data here\n",
    "\n",
    "        pass\n",
    "\n",
    "    \n",
    "\n",
    "    def __len__(self):\n",
    "\n",
    "        # Return the size of your dataset\n",
    "\n",
    "        return 100  # Example size\n",
    "\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        # Implement logic to get a single item at a given index\n",
    "\n",
    "        # For simplicity, let's return random tensors\n",
    "\n",
    "        return torch.randn(10, 64), torch.randint(0, 2, (10,))  # Example data\n",
    "\n",
    "dataset = MyDataset()\n",
    "loader = DataLoader(dataset, batch_size=32, shuffle=True, pin_memory=True)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "optimizer = Adam(model.parameters(), lr=1e-3)\n",
    "scaler = GradScaler()\n",
    "\n",
    "for epoch in range(10):  # Example: 10 epochs\n",
    "    for inputs, targets in loader:\n",
    "        inputs, targets = inputs.to(device, non_blocking=True), targets.to(device, non_blocking=True)\n",
    "        optimizer.zero_grad()\n",
    "        with autocast():\n",
    "            predictions = model(inputs)\n",
    "            loss = nn.functional.cross_entropy(predictions, targets)\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_gpu_env_llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
